category,lemmatized_text
cs.AI,occasional need return shallow point search tree existing backtracking method sometimes erase meaningful progress toward solving search problem paper present method backtrack point moved deeper search space thereby avoiding difficulty technique developed variant dependencydirected backtracking us polynomial space still providing useful control information retaining completeness guarantee provided earlier approach
cs.AI,market price system constitute wellunderstood class mechanism certain condition provide effective decentralization decision making minimal communication overhead marketoriented programming approach distributed problem solving derive activity resource allocation set computational agent computing competitive equilibrium artificial economy walras provides basic construct defining computational market structure protocol deriving corresponding price equilibrium particular realization approach form multicommodity flow problem see careful construction decision process according economic principle lead efficient distributed resource allocation behavior system meaningfully analyzed economic term
cs.AI,describe extensive study search gsat approximation procedure propositional satisfiability gsat performs greedy hillclimbing number satisfied clause truth assignment experiment provide complete picture gsats search previous account describe detail two phase search rapid hillclimbing followed long plateau search demonstrate applied randomly generated sat problem simple scaling problem size mean number satisfied clause mean branching rate result allow u make detailed numerical conjecture length hillclimbing phase average gradient phase conjecture average score average branching rate decay exponentially plateau search end showing result used direct future theoretical analysis work provides case study computer experiment used improve understanding theoretical property algorithm
cs.AI,real logic programmer normally use cut effective learning procedure logic program able deal cut predicate procedural meaning clause containing cut learned using extensional evaluation method done learning system hand searching space possible program instead space independent clause unfeasible alternative solution generate first candidate base program cover positive example make consistent inserting cut appropriate problem learning program cut investigated seems natural reasonable approach generalize scheme investigate difficulty arise major shortcoming actually caused general need intensional evaluation conclusion analysis paper suggests precise technical ground learning cut difficult current induction technique probably restricted purely declarative logic language
cs.AI,support goal allowing user record retrieve information paper describes interactive notetaking system penbased computer two distinctive feature first actively predicts user going write second automatically construct custom buttonbox user interface request system example learningapprentice software agent machine learning component characterizes syntax semantics user information performance system us learned information generate completion string construct user interface description online appendix people like record information paper initially efficient lack flexibility recording information computer le efficient powerful new note taking softwre user record information directly computer behind interface agent act user help provides default construct custom user interface demonstration quicktime movie note taking agent action file binhexed selfextracting archive macintosh utility binhex available macarchiveumichedu quicktime available ftpapplecom dtsmacsyssoftquicktime
cs.AI,terminological knowledge representation system tkrss tool designing using knowledge base make use terminological language concept language analyze theoretical point view tkrs whose capability go beyond one presently available tkrss new feature studied often required practical application summarized three main point first consider highly expressive terminological language called alcnr including general complement concept number restriction role conjunction second allow express inclusion statement general concept terminological cycle particular case third prove decidability number desirable tkrsdeduction service like satisfiability subsumption instance checking sound complete terminating calculus reasoning alcnrknowledge base calculus extends general technique constraint system byproduct proof get also result inclusion statement alcnr simulated terminological cycle descriptive semantics adopted
cs.AI,formalism presented computing organizing action autonomous agent dynamic environment introduce notion teleoreactive tr program whose execution entail construction circuitry continuous computation parameter condition agent action based addition continuous feedback tr program support parameter binding recursion primary difference tr program many circuitbased system circuitry tr program compact constructed run time thus anticipate contingency might arise possible run addition tr program intuitive easy write written form compatible automatic planning learning method briefly describe experimental application tr program control simulated actual mobile robot
cs.AI,learning past tense english verb seemingly minor aspect language acquisition generated heated debate since become landmark task testing adequacy cognitive modeling several artificial neural network anns implemented challenge better symbolic model posed paper present generalpurpose symbolic pattern associator spa based upon decisiontree learning algorithm id conduct extensive headtohead comparison generalization ability ann model spa different representation conclude spa generalizes past tense unseen verb better ann model wide margin offer insight case also discus new default strategy decisiontree learning algorithm
cs.AI,ability identify interesting repetitive substructure essential component discovering knowledge structural data describe new version subdue substructure discovery system based minimum description length principle subdue system discovers substructure compress original data represent structural concept data replacing previouslydiscovered substructure data multiple pass subdue produce hierarchical description structural regularity data subdue us computationallybounded inexact graph match identifies similar identical instance substructure find approximate measure closeness two substructure computational constraint addition minimum description length principle background knowledge used subdue guide search towards appropriate substructure experiment variety domain demonstrate subdues ability find substructure capable compressing original data discover structural concept important domain description online appendix compressed tar file containing subdue discovery system written c program accepts input database represented graph form output discovered substructure corresponding value
cs.AI,theory revision problem problem best go revising deficient domain theory using information contained example expose inaccuracy paper present approach theory revision problem propositional domain theory approach described called ptr us probability associated domain theory element numerically track flow proof theory allows u measure precise role clause literal allowing preventing desired undesired derivation given example information used efficiently locate repair flawed element theory ptr proved converge theory correctly classifies example shown experimentally fast accurate even deep theory
cs.AI,report series experiment decision tree consistent training data constructed experiment run gain understanding property set consistent decision tree factor affect accuracy individual tree particular investigated relationship size decision tree consistent training data accuracy tree test data experiment performed massively parallel maspar computer result experiment several artificial two real world problem indicate many problem investigated smaller consistent decision tree average le accurate average accuracy slightly larger tree
cs.AI,paper analyzes correctness subsumption algorithm used classic description logicbased knowledge representation system used practical application order deal efficiently individual classic description developer use algorithm incomplete respect standard modeltheoretic semantics description logic provide variant semantics description respect current implementation complete independently motivated soundness completeness polynomialtime subsumption algorithm established using description graph abstracted version implementation structure used classic independent interest
cs.AI,paper describe modify gsat applied nonclausal formula idea use particular score function give number clause cnf conversion formula false given truth assignment value computed linear time without constructing cnf conversion proposed methodology applies variant gsat proposed far
cs.AI,given knowledge base kb containing firstorder statistical fact consider principled method called randomworlds method computing degree belief formula phi hold given kb reasoning world system consisting n individual consider possible world firstorder model domain n satisfy kb compute fraction phi true define degree belief asymptotic value fraction n grows large show vocabulary underlying phi kb us constant unary predicate naturally associate entropy world n grows larger many world higher entropy therefore use maximumentropy computation compute degree belief result similar spirit previous work physic artificial intelligence far general equal interest result limitation scope importantly restriction unary predicate seems necessary although randomworlds method make sense general connection maximum entropy seems disappear nonunary case observation suggest unexpected limitation applicability maximumentropy method
cs.AI,information extraction task automatically picking information interest unconstrained text information interest usually extracted two step first sentence level processing locates relevant piece information scattered throughout text second discourse processing merges coreferential information generate output first step piece information locally identified without recognizing relationship among key word search simple pattern search achieve purpose second step requires deeper knowledge order understand relationship among separately identified piece information previous information extraction system focused first step partly required link piece information piece link extracted piece information map onto structured output format complex discourse processing essential paper report japanese information extraction system merges information using pattern matcher discourse processor evaluation result show high level system performance approach human performance
cs.AI,article describes new system induction oblique decision tree system oc combine deterministic hillclimbing two form randomization find good oblique split form hyperplane node decision tree oblique decision tree method tuned especially domain attribute numeric although adapted symbolic mixed symbolicnumeric attribute present extensive empirical study using real artificial data analyze ocs ability construct oblique tree smaller accurate axisparallel counterpart also examine benefit randomization construction oblique decision tree
cs.AI,paper introduces framework planning learning agent given goal achieve environment whose behavior partially known agent discus tractability various plandesign process show large natural class planning learning system plan presented verified reasonable time however coming algorithmically plan even simple class system apparently intractable emphasize role offline plandesign process show natural case verification projection part carried efficient algorithmic manner
cs.AI,vast amount online text available led renewed interest information extraction ie system analyze unrestricted text producing structured representation selected information text paper present novel approach us machine learning acquire knowledge higher level ie processing wrapup trainable ie discourse component make intersentential inference identifies logical relation among information extracted text previous corpusbased approach limited lower level processing partofspeech tagging lexical disambiguation dictionary construction wrapup fully trainable automatically decides classifier needed even derives feature set classifier automatically performance equal partially trainable discourse module requiring manual customization domain
cs.AI,paper multidisciplinary review empirical statistical learning graphical model perspective wellknown example graphical model include bayesian network directed graph representing markov chain undirected network representing markov field graphical model extended model data analysis empirical learning using notation plate graphical operation simplifying manipulating problem provided including decomposition differentiation manipulation probability model exponential family two standard algorithm schema learning reviewed graphical framework gibbs sampling expectation maximization algorithm using operation schema popular algorithm synthesized graphical specification includes version linear regression technique feedforward network learning gaussian discrete bayesian network data paper concludes sketching implication data analysis summarizing popular algorithm fall within framework presented main original contribution decomposition technique demonstration graphical model provide framework understanding developing complex learning algorithm
cs.AI,many year intuition underlying partialorder planning largely taken granted past year renewed interest fundamental principle underlying paradigm paper present rigorous comparative analysis partialorder totalorder planning focusing two specific planner directly compared show subtle assumption underly widespread intuition regarding supposed efficiency partialorder planning instance superiority partialorder planning depend critically upon search strategy structure search space understanding underlying assumption crucial constructing efficient planner
cs.AI,multiclass learning problem involve finding definition unknown function fx whose range discrete set containing k gt value ie k class definition acquired studying collection training example form xi f xi existing approach multiclass learning problem include direct application multiclass algorithm decisiontree algorithm c cart application binary concept learning algorithm learn individual binary function k class application binary concept learning algorithm distributed output representation paper compare three approach new technique errorcorrecting code employed distributed output representation show output representation improve generalization performance c backpropagation wide range multiclass learning task also demonstrate approach robust respect change size training sample assignment distributed representation particular class application overfitting avoidance technique decisiontree pruning finally show thatlike methodsthe errorcorrecting code technique provide reliable class probability estimate taken together result demonstrate errorcorrecting output code provide generalpurpose method improving performance inductive learning program multiclass problem
cs.AI,paradigm transformational planning casebased planning plan debugging involve process known plan adaptation modifying repairing old plan solves new problem paper provide domainindependent algorithm plan adaptation demonstrate sound complete systematic compare adaptation algorithm literature approach based view planning searching graph partial plan generative planning start graph root move node node using planrefinement operator planning adaptation library plan arbitrary node plan graph starting point search planadaptation algorithm apply refinement operator available generative planner also retract constraint step plan algorithm completeness ensures adaptation algorithm eventually search entire graph systematicity ensures without redundantly searching part graph
cs.AI,temporal difference td method constitute class method learning prediction multistep prediction problem parameterized recency factor lambda currently important application method temporal credit assignment reinforcement learning well known reinforcement learning algorithm ahc qlearning may viewed instance td learning paper examines issue efficient general implementation tdlambda arbitrary lambda use reinforcement learning algorithm optimizing discounted sum reward traditional approach based eligibility trace argued suffer inefficiency lack generality ttd truncated temporal difference procedure proposed alternative indeed approximates tdlambda requires little computation per action used arbitrary function representation method idea derived fairly simple new probably unexplored far encouraging experimental result presented suggesting using lambda gt ttd procedure allows one obtain significant learning speedup essentially cost usual td learning
cs.AI,paper introduces icet new algorithm costsensitive classification icet us genetic algorithm evolve population bias decision tree induction algorithm fitness function genetic algorithm average cost classification using decision tree including cost test feature measurement cost classification error icet compared three algorithm costsensitive classification eg csid idx also c classifies without regard cost five algorithm evaluated empirically five realworld medical datasets three set experiment performed first set examines baseline performance five algorithm five datasets establishes icet performs significantly better competitor second set test robustness icet variety condition show icet maintains advantage third set look icets search bias space discovers way improve search
cs.AI,theory revision integrates inductive learning background knowledge combining training example coarse domain theory produce accurate theory two challenge theory revision theoryguided system face first representation language appropriate initial theory may inappropriate improved theory original representation may concisely express initial theory accurate theory forced use representation may bulky cumbersome difficult reach second theory structure suitable coarse domain theory may insufficient finetuned theory system produce small local change theory limited value accomplishing complex structural alteration may required consequently advanced theoryguided learning system require flexible representation flexible structure analysis various theory revision system theoryguided learning system reveals specific strength weakness term two desired property designed capture underlying quality system new system us theoryguided constructive induction experiment three domain show improvement previous theoryguided system lead study behavior limitation potential theoryguided constructive induction
cs.AI,many study carried order increase search efficiency constraint satisfaction problem among make use structural property constraint network others take account semantic property constraint generally assuming constraint posse given property paper propose new decomposition method benefiting semantic property functional constraint bijective constraint structural property network furthermore constraint need functional show condition existence solution guaranteed first characterize particular subset variable name root set introduce pivot consistency new local consistency weak form path consistency achieved ond complexity instead ond path consistency present associated property particular show consistent instantiation root set linearly extended solution lead presentation aforementioned new method solving decomposing functional csps
cs.AI,study process multiagent reinforcement learning context load balancing distributed system without use either central coordination explicit communication first define precise framework study adaptive load balancing important feature stochastic nature purely local information available individual agent given framework show illuminating result interplay basic adaptive behavior parameter effect system efficiency investigate property adaptive load balancing heterogeneous population address issue exploration v exploitation context finally show naive use communication may improve might even harm system efficiency
cs.AI,since inception artificial intelligence relied upon theoretical foundation centered around perfect rationality desired property intelligent system argue others done foundation inadequate imposes fundamentally unsatisfiable requirement result arisen wide gap theory practice ai hindering progress field propose instead property called bounded optimality roughly speaking agent boundedoptimal program solution constrained optimization problem presented architecture task environment show construct agent property simple class machine architecture broad class realtime environment illustrate result using simple model automated mail sorting facility also define weaker property asymptotic bounded optimality abo generalizes notion optimality classical complexity theory construct universal abo program ie program abo matter realtime constraint applied universal abo program used building block complex system conclude discussion prospect bounded optimality theoretical basis ai relate similar trend philosophy economics game theory
cs.AI,present algorithm learn certain class functionfree recursive logic program polynomial time equivalence query particular show single kary recursive constantdepth determinate clause learnable twoclause program consisting one learnable recursive clause one constantdepth determinate nonrecursive clause also learnable additional basecase oracle assumed result immediately imply paclearnability class although class learnable recursive program constrained shown companion paper maximally general generalizing either class natural way lead computationally difficult learning problem thus taken together companion paper paper establishes boundary efficient learnability recursive logic program
cs.AI,companion paper shown class constantdepth determinate kary recursive clause efficiently learnable paper present negative result showing natural generalization class hard learn valiants model paclearnability particular show following program class cryptographically hard learn program unbounded number constantdepth linear recursive clause program one constantdepth determinate clause containing unbounded number recursive call program one linear recursive clause constant locality result immediately imply nonlearnability general class program also show learning constantdepth determinate program either two linear recursive clause one linear recursive clause one nonrecursive clause hard learning boolean dnf together positive result companion paper negative result establish boundary efficient learnability recursive functionfree clause
cs.AI,evidence leastcommitment planner efficiently handle planning problem involve difficult goal interaction evidence led common belief delayedcommitment best possible planning strategy however recently found evidence eagercommitment planner handle variety planning problem efficiently particular difficult operator choice resigned futility trying find universally successful planning strategy devised planner used study domain problem best planning strategy article introduce new planning algorithm flecs us flexible commitment strategy respect planstep ordering able use strategy delayedcommitment eagercommitment combination delayed eager operatorordering commitment allows flecs take advantage benefit explicitly using simulated execution state reasoning planning constraint flecs vary commitment strategy across different problem domain also course single planning problem flecs represents novel contribution planning explicitly provides choice commitment strategy use planning flecs provides framework investigate mapping planning domain problem efficient planning strategy
cs.AI,paper present method inducing logic program example learns new class concept called firstorder decision list defined ordered list clause ending cut method called foidl based foil quinlan employ intensional background knowledge avoids need explicit negative example particularly useful problem involve rule specific exception learning pasttense english verb task widely studied context symbolicconnectionist debate foidl able learn concise accurate program problem significantly fewer example previous method connectionist symbolic
cs.AI,ion one promising approach improve performance problem solver several domain abstraction dropping sentence domain description used hierarchical planner proven useful paper present example illustrate significant drawback abstraction dropping sentence overcome drawback propose general view abstraction involving change representation language developed new abstraction methodology related sound complete learning algorithm allows complete change representation language planning case concrete abstract however achieve powerful change representation language abstract language well rule describe admissible way abstracting state must provided domain model new abstraction approach core paris plan abstraction refinement integrated system system abstract planning case automatically learned given concrete case empirical study domain process planning mechanical engineering show significant advantage proposed reasoning abstract case classical hierarchical planning
cs.AI,identifying inaccurate data long regarded significant difficult problem ai paper present new method identifying inaccurate data basis qualitative correlation among related data first introduce definition related data qualitative correlation among related data put forward new concept called support coefficient function scf scf used extract represent calculate qualitative correlation among related data within dataset propose approach determining dynamic shift interval inaccurate data approach calculating possibility identifying inaccurate data respectively approach based scf finally present algorithm identifying inaccurate data using qualitative correlation among related data confirmatory disconfirmatory evidence developed practical system interpreting infrared spectrum applying method fully tested system several hundred real spectrum experimental result show method significantly better conventional method used many similar system
cs.AI,learning reasoning aspect considered intelligence study within ai separated historically learning topic machine learning neural network reasoning falling classical symbolic ai however learning reasoning many way interdependent paper discus nature interdependency proposes general framework called flare combine inductive learning using prior knowledge together reasoning propositional setting several example test framework presented including classical induction many important reasoning protocol two simple expert system
cs.AI,paper study problem ergodicity transition probability matrix markovian model hidden markov model hmms make difficult task learning represent longterm context sequential data phenomenon hurt forward propagation longterm context information well learning hidden state representation represent longterm context depends propagating credit information backwards time using result markov chain theory show problem diffusion context credit reduced transition probability approach ie transition probability matrix sparse model essentially deterministic result found paper apply learning approach based continuous optimization gradient descent baumwelch algorithm
cs.AI,symmetric network designed energy minimization boltzman machine hopfield net frequently investigated use optimization constraint satisfaction approximation nphard problem nevertheless finding global solution ie global minimum energy function guaranteed even local solution may take exponential number step propose improvement standard local activation function used network improved algorithm guarantee global minimum found linear time treelike subnetworks algorithm called activate uniform assume network treelike identify treelike subnetworks even cyclic topology arbitrary network avoid local minimum along tree acyclic network algorithm guaranteed converge global minimum initial state system selfstabilization remains correct various type scheduler negative side show presence cycle uniform algorithm exists guarantee optimality even sequential asynchronous scheduler asynchronous scheduler activate one unit time synchronous scheduler activate number unit single time step addition uniform algorithm exists optimize even acyclic network scheduler synchronous finally show algorithm improved using cyclecutset scheme general algorithm called activatewithcutset improves activate performance guarantee related size network cyclecutset
cs.AI,functionalitybased recognition system recognize object category level reasoning well object support expected function system naturally associate measure goodness membership value recognized object measure goodness result combining individual measure membership value potentially many primitive evaluation different property object shape membership function used compute membership value evaluating primitive particular physical property object previous version recognition system known gruff membership function primitive evaluation handcrafted system designer paper provide learning component gruff system called omlet automatically learns membership function given set example object labeled desired category measure learning algorithm generally applicable problem lowlevel membership value combined andor tree structure give final overall membership value
cs.AI,paper present approach learning situated interactive tutorial instruction within ongoing agent tutorial instruction flexible thus powerful paradigm teaching task allows instructor communicate whatever type knowledge agent might need whatever situation might arise support flexibility however agent must able learn multiple kind knowledge broad range instructional interaction approach called situated explanation achieves learning combination analytic inductive technique combine form explanationbased learning situated instruction full suite contextually guided response incomplete explanation approach implemented agent called instructosoar learns hierarchy new task domain knowledge interactive natural language instruction instructosoar meet three key requirement flexible instructability distinguish previous system take known unknown command instruction point handle instruction apply either current situation hypothetical situation specified language instance conditional instruction learn instruction class knowledge us perform task
cs.AI,opus branch bound search algorithm enables efficient admissible search space order search operator application significant algorithm search efficiency demonstrated respect large machine learning search space use admissible search potential value machine learning community mean exact learning bias employed complex learning task precisely specified manipulated opus also potential application area artificial intelligence notably truth maintenance
cs.AI,main aim work development visionbased road detection system fast enough cope difficult realtime constraint imposed moving vehicle application hardware platform specialpurpose massively parallel system chosen minimize system production operational cost paper present novel approach expectationdriven lowlevel image segmentation mapped naturally onto meshconnected massively parallel simd architecture capable handling hierarchical data structure input image assumed contain distorted version given template multiresolution stretching process used reshape original template accordance acquired image content minimizing potential function distorted template process output
cs.AI,area inductive learning generalization main operation usual definition induction based logical implication recently rising interest clausal representation knowledge machine learning almost inductive learning system perform generalization clause use relation thetasubsumption instead implication main reason wellknown simple technique compute least general generalization thetasubsumption implication however generalization thetasubsumption inappropriate learning recursive clause crucial problem since recursion basic program structure logic program note implication clause undecidable therefore introduce stronger form implication called timplication decidable clause show every finite set clause exists least general generalization timplication describe technique reduce generalization implication clause generalization thetasubsumption call expansion original clause moreover show every nontautological clause exists tcomplete expansion mean every generalization timplication clause reduced generalization thetasubsumption expansion
cs.AI,present definition cause effect term decisiontheoretic primitive thereby provide principled foundation causal reasoning definition departs traditional view causation causal assertion may vary set decision available argue approach provides added clarity notion cause also paper examine encoding causal relationship directed acyclic graph describe special class influence diagram canonical form show relationship pearl representation cause effect finally show canonical form facilitates counterfactual reasoning
cs.AI,characteristic model alternative model based representation horn expression shown two representation incomparable advantage therefore natural ask cost translating back forth representation interestingly translation question arise database theory application design relational database paper study computational complexity problem main result two translation problem equivalent polynomial reduction equivalent corresponding decision problem namely translating equivalent deciding whether given set model set characteristic model given horn expression also relate problem hypergraph transversal problem well known problem related application ai polynomial time algorithm known shown general translation problem least hard hypergraph transversal problem special case equivalent
cs.AI,article describes application three wellknown statistical method field gametree search using large number classified othello position feature weight evaluation function gamephaseindependent meaning estimated mean logistic regression fisher linear discriminant quadratic discriminant function normally distributed feature thereafter playing strength compared mean tournament resulting version worldclass othello program application logistic regression used first time context game playing lead better result approach
cs.AI,describe machine learning method predicting value realvalued function given value multiple input variable method induces solution sample form ordered disjunctive normal form dnf decision rule central objective method representation induction compact easily interpretable solution rulebased decision model extended search efficiently similar case prior approximating function value experimental result realworld data demonstrate new technique competitive existing machine learning statistical method sometimes yield superior regression performance
cs.AI,many application planning scheduling problem molecular biology rely heavily temporal reasoning component paper discus design empirical analysis algorithm temporal reasoning system based allen influential intervalbased framework representing temporal information core system algorithm determining whether temporal information consistent finding one scenario consistent temporal information two important algorithm task path consistency algorithm backtracking algorithm path consistency algorithm develop technique result tenfold speedup already highly optimized implementation backtracking algorithm develop variable value ordering heuristic shown empirically dramatically improve performance algorithm well show previously suggested reformulation backtracking search problem reduce time space requirement backtracking search taken together technique develop allow temporal reasoning component solve problem practical size
cs.AI,paper describes extension wellfounded semantics logic program two type negation extension information preference rule expressed logical language derived dynamically achieved using reserved predicate symbol naming technique conflict among rule resolved whenever possible basis derived preference information wellfounded conclusion prioritized logic program computed polynomial time legal reasoning example illustrates usefulness approach
cs.AI,traditional database commonly support efficient query update procedure operate time sublinear size database goal paper take first step toward dynamic reasoning probabilistic database comparable efficiency propose dynamic data structure support efficient algorithm updating querying singly connected bayesian network conventional algorithm new evidence absorbed time query processed time n size network propose algorithm preprocessing phase allows u answer query time olog n expense olog n time per evidence absorption usefulness sublinear processing time manifest application requiring near realtime response large probabilistic database briefly discus potential application dynamic probabilistic reasoning computational biology
cs.AI,introduce algorithm combinatorial search quantum computer capable significantly concentrating amplitude solution np search problem average done exploiting aspect problem structure used classical backtrack method avoid unproductive search choice quantum algorithm much likely find solution simple direct use quantum parallelism furthermore empirical evaluation small problem show quantum algorithm display phase transition behavior location seen many previously studied classical search method specifically difficult problem instance concentrated near abrupt change underconstrained overconstrained problem
cs.AI,develop mean field theory sigmoid belief network based idea statistical mechanic mean field theory provides tractable approximation true probability distribution network also yield lower bound likelihood evidence demonstrate utility framework benchmark problem statistical pattern recognitionthe classification handwritten digit
cs.AI,reported weakness c domain continuous attribute addressed modifying formation evaluation test continuous attribute mdlinspired penalty applied test eliminating consideration altering relative desirability test empirical trial show modification lead smaller decision tree higher predictive accuracy result also confirm new version c incorporating change superior recent approach use global discretization construct small tree multiinterval split
cs.AI,many type machine learning algorithm one compute statistically optimal way select training data paper review optimal data selection technique used feedforward neural network show principle may used select data two alternative statisticallybased learning architecture mixture gaussians locally weighted regression technique neural network computationally expensive approximate technique mixture gaussians locally weighted regression efficient accurate empirically observe optimality criterion sharply decrease number training example learner need order achieve good performance
cs.AI,inductive theorem provers often diverge paper describes simple critic computer program monitor construction inductive proof attempting identify diverging proof attempt divergence recognized mean difference matching procedure critic proposes lemma generalization ripple difference away proof go without divergence critic enables theorem prover spike prove many theorem completely automatically definition alone
cs.AI,termination logic program negated body atom called general logic program important topic one reason many computational mechanism used process negated atom like clark negation failure chans constructive negation based termination condition paper introduces methodology proving termination general logic program wrt prolog selection rule idea distinguish part program depending whether termination depends selection rule end notion low weakly upacceptable program introduced use notion develop methodology proving termination general logic program show interesting problem nonmonotonic reasoning formalized implemented mean terminating general logic program
cs.AI,clustering often used discovering structure data clustering system differ objective function used evaluate clustering quality control strategy used search space clustering ideally search strategy consistently construct clustering high quality computationally inexpensive well general way partition search system inexpensively construct tentative clustering initial examination followed iterative optimization continues search background improved clustering given motivation evaluate inexpensive strategy creating initial clustering coupled several control strategy iterative optimization repeatedly modifies initial clustering search better one one method appears novel iterative optimization strategy clustering context clustering constructed judged analyst often according taskspecific criterion several author abstracted criterion posited generic performance task akin pattern completion error rate completed pattern used externally judge clustering utility given performance task adapt resamplingbased pruning strategy used supervised learning system task simplifying hierarchical clustering thus promising ease postclustering analysis finally propose number objective function based attributeselection measure decisiontree induction might perform well error rate simplicity dimension
cs.AI,paper present new experimental evidence utility occam razor asystematic procedure presented postprocessing decision tree produced c procedure derived rejecting occam razor instead attending assumption similar object likely belong class increase decision tree complexity without altering performance tree training data inferred resulting complex decision tree demonstrated average variety common learning task higher predictive accuracy le complex original decision tree result raise considerable doubt utility occam razor commonly applied modern machine learning
cs.AI,main operation inductive logic programming ilp generalization specialization make sense generality order ilp three important generality order subsumption implication implication relative background knowledge two language used often language clause language horn clause give total six different ordered language paper give systematic treatment existence nonexistence least generalization greatest specialization finite set clause six ordered set survey result already obtained others also contribute answer main new result firstly existence computable least generalization implication every finite set clause containing least one nontautologous functionfree clause among necessarily functionfree clause secondly show least generalization need exist relative implication even set generalized background knowledge functionfree thirdly give complete discussion existence nonexistence greatest specialization six ordered language
cs.AI,paper survey field reinforcement learning computerscience perspective written accessible researcher familiar machine learning historical basis field broad selection current work summarized reinforcement learning problem faced agent learns behavior trialanderror interaction dynamic environment work described resemblance work psychology differs considerably detail use word reinforcement paper discus central issue reinforcement learning including trading exploration exploitation establishing foundation field via markov decision theory learning delayed reinforcement constructing empirical model accelerate learning making use generalization hierarchy coping hidden state concludes survey implemented system assessment practical utility current method reinforcement learning
cs.AI,although scheduling problem nphard domain specific technique perform well practice quite expensive construct adaptive problemsolving solving domain specific knowledge acquired automatically general problem solver flexible control architecture approach learning system explores space possible heuristic method one wellsuited eccentricity given domain problem distribution article discus application approach scheduling satellite communication using problem distribution based actual mission requirement approach identifies strategy decrease amount cpu time required produce schedule also increase percentage problem solvable within computational resource limitation
cs.AI,speedup learning seek improve computational efficiency problem solving experience paper develop formal framework learning efficient problem solving random problem solution apply framework two different representation learned knowledge namely control rule macrooperators prove theorem identify sufficient condition learning representation proof constructive accompanied learning algorithm framework capture empirical explanationbased speedup learning unified fashion illustrate framework implementation two domain symbolic integration eight puzzle work integrates many strand experimental theoretical work machine learning including empirical learning control rule macrooperator learning explanationbased learning ebl probably approximately correct pac learning
cs.AI,fundamental assumption made classical ai planner uncertainty world planner full knowledge condition plan executed outcome every action fully predictable planner therefore construct contingency plan ie plan different action performed different circumstance paper discus issue arise representation construction contingency plan describe cassandra partialorder contingency planner cassandra us explicit decisionsteps enable agent executing plan decide plan branch follow decisionsteps plan result subgoals acquire knowledge planned way subgoals cassandra thus distinguishes process gathering information process making decision explicit representation decision cassandra allows coherent approach problem contingent planning provides solid base extension use different decisionmaking procedure
cs.AI,important problem geometric reasoning find configuration collection geometric body satisfy set given constraint recently suggested problem solved efficiently symbolically reasoning geometry approach called degree freedom analysis employ set specialized routine called plan fragment specify change configuration set body satisfy new constraint preserving existing constraint potential drawback limit scalability approach concerned difficulty writing plan fragment paper address limitation showing plan fragment automatically synthesized using first principle geometric body action topology
cs.AI,motivated control theoretic distinction controllable uncontrollable event distinguish two type agent within multiagent system controllable agent directly controlled system designer uncontrollable agent designer direct control refer system partially controlled multiagent system investigate one might influence behavior uncontrolled agent appropriate design controlled agent particular wish understand problem naturally described term method applied influence uncontrollable agent effectiveness method whether similar method work across different domain using gametheoretic framework paper study design partially controlled multiagent system two context one context uncontrollable agent expected utility maximizers reinforcement learner suggest different technique controlling agent behavior domain ass success examine relationship
cs.AI,visual thinking play important role scientific reasoning based research automating diverse reasoning task dynamical system nonlinear controller kinematic mechanism fluid motion identified style visual thinking imagistic reasoning imagistic reasoning organizes computation around imagelike analogue representation perceptual symbolic operation brought bear infer structure behavior program incorporating imagistic reasoning shown perform expert level domain defy current analytic numerical method developed computational paradigm spatial aggregation unify description class imagistic problem solver program written paradigm following property take continuous field optional objective function input produce highlevel description structure behavior control action computes multilayer intermediate representation called spatial aggregate forming equivalence class adjacency relation employ small set generic operator aggregation classification localization perform bidirectional mapping informationrich field successively abstract spatial aggregate us data structure neighborhood graph common interface modularize computation illustrate theory describe computational structure three implemented problem solver kam map hipair term spatial aggregation generic operator mixing matching library commonly used routine
cs.AI,finding stable model knowledge base significant computational problem artificial intelligence task computational heart truth maintenance system autoepistemic logic default logic unfortunately nphard paper present hierarchy class knowledge base omegaomega following property first omega class stratified knowledge base second knowledge base pi omegak pi k stable model may found time olnk l length knowledge base n number atom pi third arbitrary knowledge base pi find minimum k pi belongs omegak time polynomial size pi last k class knowledge base case unioni infty omegai k every knowledge base belongs class hierarchy
cs.AI,propose domainindependent technique bringing wellfounded partialorder planner closer practicality first two technique aimed improving search control keeping overhead cost low one based simple adjustment default heuristic used ucpop select plan refinement based preferring zero commitment forced plan refinement whenever possible using lifo prioritization otherwise radical technique use operator parameter domain prune search domain initially computed definition operator initial goal condition using polynomialtime algorithm propagates set constant operator graph starting initial condition planning parameter domain used prune nonviable operator instance remove spurious clobbering threat experiment based modification ucpop improved plan goal selection strategy gave speedup factor ranging variety problem nontrivial unmodified version crucially hardest problem gave greatest improvement pruning technique based parameter domain often gave speedup order magnitude difficult problem default ucpop search strategy improved strategy lisp code technique test problem provided online appendix
cs.AI,cue phrase may used discourse sense explicitly signal discourse structure also sentential sense convey semantic rather structural information correctly classifying cue phrase discourse sentential critical natural language processing system exploit discourse structure eg performing task anaphora resolution plan recognition paper explores use machine learning classifying cue phrase discourse sentential two machine learning program cgrendel c used induce classification model set preclassified cue phrase feature text speech machine learning shown effective technique automating generation classification model also improving upon previous result compared manually derived classification model already literature learned model often perform higher accuracy contain new linguistic insight data addition ability automatically construct classification model make easier comparatively analyze utility alternative feature representation data finally ease retraining make learning approach scalable flexible manual method
cs.AI,paper lay part groundwork domain theory negotiation way classifying interaction clear given domain negotiation mechanism strategy appropriate define state oriented domain general category interaction necessary sufficient condition cooperation outlined use notion worth altered definition utility thus enabling agreement wider class jointgoal reachable situation approach offered conflict resolution shown even conflict situation partial cooperative step taken interacting agent agent fundamental conflict might still agree cooperate certain point unified negotiation protocol unp developed used type encounter shown certain borderline cooperative situation partial cooperative agreement ie one achieve agent goal might preferred agent even though exists rational agreement would achieve goal finally analyze case agent incomplete information goal worth agent first consider case agent goal private information analyze goal declaration strategy agent might adopt increase utility consider situation agent goal therefore standalone cost common knowledge worth attach goal private information introduce two mechanism one strict tolerant analyze affect stability efficiency negotiation outcome
cs.AI,firstorder learning involves finding clauseform definition relation example relation relevant background information paper particular firstorder learning system modified customize finding definition functional relation restriction lead faster learning time case definition higher predictive accuracy firstorder learning system might benefit similar specialization
cs.AI,paper describes extension constraint satisfaction problem csp called muse csp multiply segmented constraint satisfaction problem extension especially useful problem segment multiple set partially shared variable problem arise naturally signal processing application including computer vision speech processing handwriting recognition application often difficult segment data one way given lowlevel information utilized segmentation algorithm muse csp used compactly represent several similar instance constraint satisfaction problem multiple instance csp common variable domain constraint combined single instance muse csp reducing work required apply constraint introduce concept muse node consistency muse arc consistency muse path consistency demonstrate muse csp used compactly represent lexically ambiguous sentence multiple sentence hypothesis often generated speech recognition algorithm grammar constraint used provide par syntactically correct sentence algorithm muse arc path consistency provided finally discus create muse csp set csps labeled indicate variable shared single csp
cs.AI,new method proposed exploiting causal independency exact bayesian network inference bayesian network viewed representing factorization joint probability multiplication set conditional probability present notion causal independence enables one factorize conditional probability combination even smaller factor consequently obtain finergrain factorization joint probability new formulation causal independence let u specify conditional probability variable given parent term associative commutative operator sum max contribution parent start simple algorithm bayesian network inference given evidence query variable us factorization find posterior distribution query show algorithm extended exploit causal independence empirical study based cpcs network medical diagnosis show method efficient previous method allows inference larger network previous algorithm
cs.AI,efficiently entering information computer key enjoying benefit computing paper describes three intelligent user interface handwriting recognition adaptive menu predictive fillin context adding personus name address electronic organizer test show handwriting recognition slower typing onscreen soft keyboard adaptive menu predictive fillin twice fast paper also present strategy applying three interface information collection domain
cs.AI,decomposable dependency model posse number interesting useful property paper present new characterization decomposable model term independence relationship obtained adding single axiom wellknown set characterizing dependency model isomorphic undirected graph also briefly discus potential application result problem learning graphical model data
cs.AI,instancebased learning technique typically handle continuous linear input value well often handle nominal input attribute appropriately value difference metric vdm designed find reasonable distance value nominal attribute value largely ignores continuous attribute requiring discretization map continuous value nominal value paper proposes three new heterogeneous distance function called heterogeneous value difference metric hvdm interpolated value difference metric ivdm windowed value difference metric wvdm new distance function designed handle application nominal attribute continuous attribute experiment application new distance metric achieve higher classification accuracy average three previous distance function datasets nominal continuous attribute
cs.AI,previous approach analyzing spontaneously spoken language often based encoding syntactic semantic knowledge manually symbolically progress using statistical connectionist language model many current spoken language system still use relatively brittle handcoded symbolic grammar symbolic semantic component contrast describe socalled screening approach learning robust processing spontaneously spoken language screening approach flat analysis us shallow sequence category representation analyzing utterance various syntactic semantic dialog level rather using deeply structured symbolic analysis use flat connectionist analysis screening approach aim supporting speech language processing using datadriven learning robustness connectionist network order test approach developed screen system based new robust learned flat analysis paper focus detailed description screen architecture flat syntactic semantic analysis interaction speech recognizer detailed evaluation analysis robustness influence noisy incomplete input main result paper flat representation allow robust processing spontaneous spoken language deeply structured representation particular show faulttolerance learning capability connectionist network support flat analysis providing robust spokenlanguage processing within overall hybrid symbolicconnectionist framework
cs.AI,modern formalism used database artificial intelligence describing application domain based notion class concept relationship among class one interesting feature formalism possibility defining class ie providing set property precisely characterize instance class many recent article point several way assigning meaning class definition containing sort recursion paper argue instead choosing single style semantics achieve better result adopting formalism allows different semantics coexist demonstrate feasibility argument presenting knowledge representation formalism description logic mualcq characteristic addition construct conjunction disjunction negation quantifier qualified number restriction mualcq includes special fixpoint construct express suitably interpreted recursive definition construct enable usual framebased description combined definition recursive data structure directed acyclic graph list stream etc establish several property mualcq including decidability computational complexity reasoning formulating correspondence particular modal logic program called modal mucalculus
cs.AI,argue analysis agentenvironment interaction extended include convention invariant maintained agent throughout activity refer thicker notion environment lifeworld present partial set formal tool describing structure lifeworlds way computationally simplify activity one specific example apply tool analysis toast system show version system different control structure fact implement common control structure together different convention encoding task state position state object environment
cs.AI,describe new paradigm implementing inference belief network consists two step compiling belief network arithmetic expression called query dag qdag answering query using simple evaluation algorithm node qdag represents numeric operation number symbol evidence leaf node qdag represents answer network query probability event interest appears qdags generated using standard algorithm exact inference belief network show generated using clustering conditioning algorithm time space complexity qdag generation algorithm worse time complexity inference algorithm based complexity qdag evaluation algorithm linear size qdag inference amount standard evaluation arithmetic expression represents intended value qdags reducing software hardware resource required utilize belief network online realworld application proposed framework also facilitates development online inference different software hardware platform due simplicity qdag evaluation algorithm interestingly enough qdags found serve purpose simple technique reducing qdags tend subsume relatively complex optimization technique beliefnetwork inference networkpruning computationcaching
cs.AI,algorithm learns set example ideally able exploit available resource abundant computing power b domainspecific knowledge improve ability generalize connectionist theoryrefinement system use background knowledge select neural network topology initial weight proven effective exploiting domainspecific knowledge however exploit available computing power weakness occurs lack ability refine topology neural network produce thereby limiting generalization especially given impoverished domain theory present regent algorithm us domainspecific knowledge help create initial population knowledgebased neural network b genetic operator crossover mutation specifically designed knowledgebased network continually search better network topology experiment three realworld domain indicate new algorithm able significantly increase generalization compared standard connectionist theoryrefinement system well previous algorithm growing knowledgebased network
cs.AI,several recent study compared relative efficiency alternative flaw selection strategy partialorder causal link pocl planning review literature present new experimental result generalize earlier work explain discrepancy particular describe leastcost flaw repair lcfr strategy developed analyzed joslin pollack compare strategy including gerevini schubert zlifo strategy lcfr zlifo make different apparently conflicting claim effective way reduce searchspace size pocl planning resolve conflict arguing much benefit gerevini schubert ascribe lifo component zlifo strategy better attributed cause show many problem strategy combine leastcost flaw selection delay separable threat effective reducing searchspace size without excessive computational overhead although strategy thus provides good default also show certain domain characteristic may reduce effectiveness
cs.AI,investigate computational property spatial algebra rcc restricted version rcc framework spatial reasoning satisfiability problem rcc known npcomplete much known approximately four billion subclass provide complete classification satisfiability subclass polynomial npcomplete respectively process identify maximal tractable subalgebras four total
cs.AI,easyhardeasy pattern difficulty combinatorial search problem constraint added explained due competition decrease number solution increased pruning test generality explanation examining one prediction number solution held fixed choice problem increased pruning lead monotonic decrease search cost instead find easyhardeasy pattern median search cost even number solution held constant search method generalizes previous observation pattern show existing theory explain full range peak search cost case pattern appears due change size minimal unsolvable subproblems rather changing number solution
cs.AI,paper combine two important direction research temporal resoning finding maximal tractable subclass allen interval algebra reasoning metric temporal information eight new maximal tractable subclass allen interval algebra presented subsuming previously reported tractable algebra algebra allow metric temporal constraint interval starting ending point using recent framework horn dlrs two algebra express notion sequentiality interval first algebra admitting qualitative metric time
cs.AI,starting likelihood preference order world extend likelihood ordering set world natural way examine resulting logic lewis earlier considered notion relative likelihood context studying counterfactuals assumed total preference order world complication arise examining partial order present total order subtlety involving exact approach lifting order world order set world addition axiomatization logic relative likelihood case partial order give insight connection relative likelihood default reasoning
cs.AI,many ai researcher today striving build agent team complex dynamic multiagent domain intended application arena education training entertainment information integration collective robotics unfortunately uncertainty complex dynamic domain obstruct coherent teamwork particular team member often encounter differing incomplete possibly inconsistent view environment furthermore team member unexpectedly fail fulfilling responsibility discover unexpected opportunity highly flexible coordination communication key addressing uncertainty simply fitting individual agent precomputed coordination plan inflexibility cause severe failure teamwork domainspecificity hinders reusability central hypothesis key flexibility reusability providing agent general model teamwork agent exploit model autonomously reason coordination communication providing requisite flexibility furthermore model enable reuse across domain saving implementation effort enforcing consistency article present one general implemented model teamwork called steam basic building block teamwork steam joint intention cohen levesque b teamwork steam based agent building partial hierarchy joint intention hierarchy seen parallel grosz krauss partial sharedplans furthermore steam team member monitor team individual member performance reorganizing team necessary finally decisiontheoretic communication selectivity steam ensures reduction communication overhead teamwork appropriate sensitivity environmental condition article describes steam application three different complex domain present detailed empirical result
cs.AI,sequitur algorithm infers hierarchical structure sequence discrete symbol replacing repeated phrase grammatical rule generates phrase continuing process recursively result hierarchical representation original sequence offer insight lexical structure algorithm driven two constraint reduce size grammar produce structure byproduct sequitur break new ground operating incrementally moreover method simple structure permit proof operates space time linear size input implementation process symbol per second applied extensive range real world sequence
cs.AI,casebased planning cbp provides way scaling domainindependent planning solve large problem complex domain replaces detailed lengthy search solution retrieval adaptation previous planning experience general cbp demonstrated improve performance generative fromscratch planning however performance improvement provides dependent adequate judgement problem similarity particular although cbp may substantially reduce planning effort overall subject misretrieval problem success cbp depends retrieval error relatively rare paper describes design implementation replay framework casebased planner dersnlpebl dersnlpebl extends current cbp methodology incorporating explanationbased learning technique allow explain learn retrieval failure encounter technique used refine judgement case similarity response feedback wrong decision made failure analysis used building case library addition repairing case large problem split stored single goal subproblems multigoal problem stored smaller case fail merged full solution empirical evaluation approach demonstrates advantage learning experienced retrieval failure
cs.AI,partially observable markov decision process pomdps natural model planning problem effect action nondeterministic state world completely observable difficult solve pomdps exactly paper proposes new approximation scheme basic idea transform pomdp another one additional information provided oracle oracle informs planning agent current state world certain region transformed pomdp consequently said region observable easier solve original pomdp propose solve transformed pomdp use optimal policy construct approximate policy original pomdp controlling amount additional information oracle provides possible find proper tradeoff computational time approximation quality term algorithmic contribution study detail exploit region observability solving transformed pomdp facilitate study also propose new exact algorithm general pomdps algorithm conceptually simple yet significantly efficient previous exact algorithm
cs.AI,model nonbayesian agent face repeated game incomplete information nature appropriate tool modeling general agentenvironment interaction model environment state controlled nature may change arbitrarily feedbackreward function initially unknown agent bayesian form prior probability neither state selection strategy nature reward function policy agent function assigns action every history observation action two basic feedback structure considered one perfect monitoring case agent able observe previous environment state part feedback imperfect monitoring case available agent reward obtained setting refer partially observable process current environment state unknown main result refers competitive ratio criterion perfect monitoring case prove existence efficient stochastic policy ensures competitive ratio obtained almost stage arbitrarily high probability efficiency measured term rate convergence shown optimal policy exist imperfect monitoring case moreover proved perfect monitoring case exist deterministic policy satisfies long run optimality criterion addition discus maxmin criterion prove deterministic efficient optimal strategy exist imperfect monitoring case criterion finally show approach longrun optimality viewed qualitative distinguishes previous work area
cs.AI,local search algorithm combinatorial search problem frequently encounter sequence state impossible improve value objective function move region called plateau move dominate time spent local search analyze characterize plateau three different class randomly generated boolean satisfiability problem identify several interesting feature plateau impact performance local search algorithm show local minimum tend small occasionally may large also show local minimum escaped without unsatisfying large number clause systematically searching escape route may computationally expensive local minimum large show plateau exit called bench tend much larger minimum bench exit state local search use escape show solution ie global minimum randomly generated problem instance form cluster behave similarly local minimum revisit several enhancement local search algorithm explain performance light result finally discus strategy creating next generation local search algorithm
cs.AI,assessment bidirectional heuristic search incorrect since first published quarter century ago quite long time search strategy achieve expected result major misunderstanding reason behind although still widespread belief bidirectional heuristic search afflicted problem search frontier passing demonstrate conjecture wrong based finding present new generic approach bidirectional heuristic search new approach dynamically improving heuristic value feasible bidirectional search approach put perspective traditional recently proposed approach order facilitate better overall understanding empirical result experiment new approach show bidirectional heuristic search performed efficiently also limited memory result suggest bidirectional heuristic search appears better solving certain difficult problem corresponding unidirectional search provides evidence usefulness search strategy long neglected summary show bidirectional heuristic search viable consequently propose reconsidered
cs.AI,approximating general formula horn formula horn envelope horn core respectively proposed selman kautz form knowledge compilation supporting rapid approximate reasoning negative side scheme static support update certain complexity drawback pointed kavvadias papadimitriou sideri hand many framework scheme proposed literature theory update revision plagued serious complexitytheoretic impediment even horn case pointed eiter gottlob demonstrated present paper fundamentally scheme inductive may lose single update positive property represented set formula small size horn structure etc paper propose new scheme incremental recompilation combine horn approximation modelbased update scheme inductive efficient free problem facing constituent set formula represented upper lower horn approximation update replace upper horn formula horn envelope minimumchange update similarly lower one horn core update key fact enables scheme horn envelope core easy compute underlying formula result minimumchange update horn formula clause conjecture efficient algorithm possible complex update
cs.AI,important characteristic many logic artificial intelligence nonmonotonicity mean adding formula premise invalidate consequence may however exist formula always safely added premise without destroying consequence say respect monotonicity also may formula consequence invalidated adding formula premise call conservative study two class formula preferential logic show closely linked formula whose truthvalue preserved along preferential ordering consider preferential logic illustration prove syntactic characterization result result paper may improve efficiency theorem provers preferential logic
cs.AI,existing plan synthesis approach artificial intelligence fall two category domain independent domain dependent domain independent approach applicable across variety domain may efficient one given domain domain dependent approach need redesigned domain separately efficient domain designed one enticing alternative approach automatically synthesize domain independent planner given knowledge domain theory planning paper investigate feasibility using existing automated software synthesis tool support synthesis specifically describe architecture called clay kestrel interactive development system kid used derive domaincustomized planner semiautomatic combination declarative theory planning declarative control knowledge specific given domain semiautomatically combine derive domaincustomized planner discus mean write declarative theory planning control knowledge kid illustrate approach generating class domainspecific planner using state space refinement experiment show synthesized planner outperform classical refinement planner implemented instantiation ucp kambhampati srivastava using control knowledge contrast cost benefit synthesis approach conventional method customizing domain independent planner
cs.AI,paper introduces new algorithm data structure quick counting machine learning datasets focus counting task constructing contingency table approach also applicable counting number record dataset match conjunctive query subject certain assumption cost operation shown independent number record dataset loglinear number nonzero entry contingency table provide sparse data structure adtree minimize memory use provide analytical worstcase bound structure several model data distribution empirically demonstrate tractablysized data structure produced large realworld datasets using sparse tree structure never allocates memory count zero b never allocating memory count deduced count c bothering expand tree fully near leaf show adtree used accelerate bayes net structure finding algorithm rule learning algorithm feature selection algorithm provide number empirical result comparing adtree method traditional direct counting approach also discus possible us adtrees machine learning method discus merit adtrees comparison alternative representation kdtrees rtrees frequent set
cs.AI,paper consider problem theory patching given domain theory whose component indicated possibly flawed set labeled training example domain concept theory patching problem revise indicated component theory resulting theory correctly classifies training example theory patching thus type theory revision revision made individual component theory concern paper determine class logical domain theory theory patching problem tractable consider propositional firstorder domain theory show theory patching problem equivalent determining information contained theory stable regardless revision might performed theory show determining stability tractable input theory satisfies two condition revision theory component monotonic effect classification example theory component act independently classification example theory also show concept introduced used determine soundness completeness particular theory patching algorithm
cs.AI,paper reinvestigate windowing rule learning algorithm show contrary previous result decision tree learning windowing fact achieve significant runtime gain noisefree domain explain different behavior rule learning algorithm fact learn rule independently main contribution paper integrative windowing new type algorithm exploit property integrating good rule final theory right discovered thus avoids relearning rule subsequent iteration windowing process experimental evidence variety noisefree domain show integrative windowing fact achieve substantial runtime gain furthermore discus problem noise windowing present algorithm able achieve runtime gain set experiment simple domain artificial noise
cs.AI,paper present comprehensive approach modelbased diagnosis includes proposal characterizing computing preferred diagnosis assuming system description augmented system structure directed graph explicating interconnection system component specifically first introduce notion consequence syntactically unconstrained propositional sentence characterizes consistencybased diagnosis show standard characterization diagnosis minimal conflict correspond syntactic variation consequence second propose new syntactic variation consequence known negation normal form nnf discus merit compared standard variation third introduce basic algorithm computing consequence nnf given structured system description show system structure contain cycle always linearsize consequence nnf computed linear time arbitrary system structure show precise connection complexity computing consequence topology underlying system structure finally present algorithm enumerates preferred diagnosis characterized consequence algorithm shown take linear time size consequence preference criterion satisfies general condition
cs.AI,one common mechanism used speeding problem solver macrolearning macro sequence basic operator acquired problem solving macro used problem solver basic operator major problem macrolearning present vast number macro available acquisition macro increase branching factor search space severely degrade problemsolving efficiency make macro learning useful program must selective acquiring utilizing macro paper describes general method selective acquisition macro solvable training problem generated increasing order difficulty macro acquired take problem solver local minimum better state utility method demonstrated several domain including domain nxn slidingtile puzzle learning small puzzle system able efficiently solve puzzle size
cs.LG,paper present maxq approach hierarchical reinforcement learning based decomposing target markov decision process mdp hierarchy smaller mdps decomposing value function target mdp additive combination value function smaller mdps paper defines maxq hierarchy prof formal result representational power establishes five condition safe use state abstraction paper present online modelfree learning algorithm maxqq prof converges wih probability kind locallyoptimal policy known recursively optimal policy even presence five kind state abstraction paper evaluates maxq representation maxqq series experiment three domain show experimentally maxqq state abstraction converges recursively optimal policy much faster flat q learning fact maxq learns representation value function important benefit make possible compute execute improved nonhierarchical policy via procedure similar policy improvement step policy iteration paper demonstrates effectiveness nonhierarchical execution experimentally finally paper concludes comparison related work discussion design tradeoff hierarchical reinforcement learning
cs.LG,many researcher explored method hierarchical reinforcement learning rl temporal abstraction abstract action defined perform many primitive action terminating however little known learning state abstraction aspect state space ignored previous work developed maxq method hierarchical rl paper define five condition state abstraction combined maxq value function decomposition prove maxqq learning algorithm converges condition show experimentally state abstraction important successful application maxqq learning
cs.LG,multiplicative newtonlike method developed author et al extended situation dynamic restricted orthogonal group general framework constructed without specifying cost function though restriction orthogonal group make problem somewhat complicated explicit expression amount individual jump obtained algorithm exactly secondorderconvergent global instability inherent newton method remedied levenbergmarquardttype variation method thus constructed readily applied independent component analysis remarkable performance illustrated numerical simulation
cs.LG,construct new algorithm scratch use fourth order cumulant stochastic variable cost function multiplicative updating rule constructed natural homogeneous nature lie group numerous merit rigorous treatment dynamic one consequence second order convergence shown cost function function invariant componentwise scaling choosen identifying point transformed scaling assume dynamic coset space method point move toward direction coset thus prewhitening required
cs.LG,given reference computer kolmogorov complexity well defined function binary string standard approach however asymptotic property function considered depend reference computer argue approach useful refined include important practical case simple binary string kolmogorov complexity calculus may developed case restrict class available reference computer interesting problem define class computer restricted natural way modeling reallife situation limited class computer physically available u give example natural restriction might look like mathematically show restriction error term even logarithmic complexity disappear standard complexity calculus keywords kolmogorov complexity algorithmic information theory
cs.LG,realworld environment usually difficult specify target operating condition precisely example target misclassification cost uncertainty make building robust classification system problematic show possible build hybrid classifier perform least well best available classifier target condition case performance hybrid actually surpass best known classifier robust performance extends across wide variety comparison framework including optimization metric accuracy expected cost lift precision recall workforce utilization hybrid also efficient build store update hybrid based method comparison classifier performance robust imprecise class distribution misclassification cost roc convex hull rocch method combine technique roc analysis decision analysis computational geometry adapts particular analyzing learned classifier method efficient incremental minimizes management classifier performance data allows clear visual comparison sensitivity analysis finally point empirical evidence robust hybrid classifier indeed needed many realworld problem
cs.LG,approach clustering presented adapts basic topdown induction decision tree method towards clustering aim employ principle instance based learning resulting methodology implemented tic top induction clustering tree system first order clustering tic system employ first order logical decision tree representation inductive logic programming system tilde various experiment tic presented propositional relational domain
cs.LG,comparing inductive logic programming ilp attributevalue learning technique tradeoff expressive power efficiency inductive logic programming technique typically expressive also le efficient therefore data set handled current inductive logic programming system small according general standard within data mining community main source inefficiency lie assumption several example may related handled independently within learning interpretation framework inductive logic programming assumption unnecessary allows scale existing ilp algorithm paper explain learning setting context relational database relate setting propositional data mining classical ilp setting show learning interpretation corresponds learning multiple relation thus extends expressiveness propositional learning maintaining efficiency large extent case classical ilp setting case study present two alternative implementation ilp system tilde topdown induction logical decision tree tildeclassic load data main memory tildelds load example one one experimentally compare implementation showing tildelds handle large data set order example mb indeed scale linearly number example
cs.LG,order agent perform well partially observable domain usually necessary action depend history observation paper explore stigmergic approach agent action include ability set clear bit external memory external memory included part input agent case need learn reactive policy highly nonmarkovian domain explore two algorithm sarsalambda empirical success partially observable domain vaps new algorithm due baird moore convergence guarantee partially observable domain compare performance two algorithm benchmark problem
cs.LG,crossvalidation useful generally applicable technique often employed machine learning including decision tree induction important disadvantage straightforward implementation technique computational overhead paper show decision tree computational overhead crossvalidation reduced significantly integrating crossvalidation normal decision tree induction process discus existing decision tree algorithm adapted aim provide analysis speedup adaptation may yield analysis supported experimental result
cs.LG,markov blanket bayesian classifier recentlyproposed algorithm construction probabilistic classifier paper present empirical comparison mbbc algorithm three bayesian classifier naive bayes treeaugmented naive bayes general bayesian network implemented using k framework cooper herskovits classifier compared term performance using simple accuracy measure roc curve speed range standard benchmark data set concluded mbbc competitive term speed accuracy algorithm considered
cs.LG,biological data often case observed data available subset sample kernel matrix derived data leave entry unavailable sample missing paper make use parametric model kernel matrix estimate missing entry fitting model existing entry parametric model created set spectral variant complete kernel matrix derived another information source model fitting adopt em algorithm based information geometry positive definite matrix report promising result bacteria clustering experiment using two marker sequence gyrb
cs.LG,learn statistical dependency among random variable requires exponentially large sample size number observed random variable arbitrary joint probability distribution occur consider case sparse data strongly suggest probability described simple bayesian network ie graph small indegree delta simple law also explain data high confidence shown calculating bound vc dimension set probability measure correspond simple graph allows select network structural risk minimization give reliability bound error estimated joint measure without contrast previous paper prior assumption set possible joint measure complexity searching optimal bayesian network indegree delta increase polynomially number random varibales constant delta optimal joint measure associated given graph found convex optimization
cs.LG,make progress two important problem regarding attribute efficient learnability first give algorithm learning decision list length k n variable using tildeok log n example time ntildeok first algorithm learning decision list subexponential sample complexity subexponential running time relevant parameter approach establishes relationship attribute efficient learning polynomial threshold function based new construction low degree low weight polynomial threshold function decision list wide range parameter construction match lower bound due beigel oddmaxbit predicate give essentially optimal tradeoff polynomial threshold function degree weight second give algorithm learning unknown parity function k n variable using onk example time polynomial n kolog n yield polynomial time algorithm sample complexity first polynomial time algorithm learning parity superconstant number variable sublinear sample complexity
cs.LG,using naive bayes email classification become popular within last month quite easy implement efficient paper want present empirical result email classification using combination naive bayes knearest neighbor search using technique show accuracy bayes filter improved slightly high number feature significantly small number feature
cs.LG,offered pool test point different subject different aspect subject together order get unitary rating score way nonlinear transformation indicator point accordance zipfs distribution proposed use wellstudied distribution intellectuality quotient iq reference distribution latent variable progress study
cs.LG,last year timeseries mining become challenging issue researcher important application lie monitoring purpose require analyzing large set timeseries learning usual pattern deviation learned profile considered unexpected situation moreover complex application may involve temporal study several heterogeneous parameter paper propose method mining heterogeneous multivariate timeseries learning meaningful pattern proposed approach allows mixed timeseries containing pattern nonpattern data imprecise match outlier stretching global translating pattern instance time present early result approach context monitoring health status person home purpose build behavioral profile person analyzing time variation several quantitative qualitative parameter recorded provision sensor installed home
cs.LG,discus stability class learning algorithm respect noisy label algorithm consider regression involve minimization regularized risk functionals lf n sumi fxiyi lambda fh shall call algorithm stable yi noisy version fxi function f h output algorithm converges f regularization term noise simultaneously vanish consider two flavor problem one data set n point remains fixed n infinity case n infinity give condition convergence fe function expectation yx x lambda fixed n case describe limiting nonnoisy nonregularized function f give condition convergence process develop set tool dealing functionals lf applicable many problem learning theory
cs.LG,consider probability hierarchy popperian finite learning study general property hierarchy prove probability hierarchy decidable ie exists algorithm receives p p answer whether pfintype learning probability success p equivalent pfintype learning probability success p prove result analyze topological structure probability hierarchy prove wellordered descending ordering orderequivalent ordinal epsilon show structure hierarchy complicated using similar method also prove pfintype learning team learning probabilistic learning power
cs.LG,analyze new algorithm probability forecasting binary observation basis available data without making assumption way observation generated algorithm shown well calibrated good resolution long enough sequence observation suitable choice parameter kernel cartesian product forecast space data space main result nonasymptotic establish explicit inequality shown tight performance algorithm
cs.LG,consider general class forecasting protocol called linear protocol discus several important special case including multiclass forecasting forecasting formalized game three player reality whose role generate observation forecaster whose goal predict observation skeptic try make money lack agreement forecaster prediction actual observation main mathematical result continuous strategy skeptic linear protocol exists strategy forecaster allow skeptic capital grow result metatheorem allows one transform continuous law probability linear protocol forecasting strategy whose prediction guaranteed satisfy law apply metatheorem weak law large number hilbert space obtain version k prediction algorithm linear protocol show version also satisfies attractive property proper calibration resolution suitable choice kernel parameter assumption way data generated
cs.LG,article offer parameter model testing difference ability level examinee item difficulty examinee discrimination item discrimination model parameter
cs.LG,propose new framework building evaluating machine learning algorithm argue many realworld problem require agent must quickly learn respond demand yet continue perform respond new training throughout useful life give framework agent built describe several metric evaluating show subtle change system construction significantly affect agent performance
cs.LG,present work new methodology design kernel data structured smaller component text image sequence methodology template procedure applied kernel measure take advantage detailed bag component representation object obtain detailed description consider possible decomposition original bag collection nested bag following prior knowledge object structure consider smaller bag compare two object detailed perspective stressing local match smaller bag global coarse perspective considering entire bag multiresolution approach likely best suited task coarse approach precise enough subtle mixture local global similarity necessary compare object approach presented would computationally tractable without factorization trick introduce presenting promising result image retrieval task
cs.LG,paper show universal learning achieved expert advice aim specify expert algorithm following characteristic us feedback action actually chosen bandit setup b applied countably infinite expert class c cope loss may grow time appropriately slowly prove loss bound adaptive adversary obtain master algorithm reactive expert problem mean master action may influence behavior adversary algorithm significantly outperform standard expert algorithm problem finally combine universal expert class resulting universal learner performs certain sense almost well computable strategy online decision problem also specify worstcase convergence speed slow
cs.LG,main problem follow perturbed leader strategy online decision problem regret bound typically proven oblivious adversary partial observation case clear obtain performance guarantee adaptive adversary without worsening bound propose conceptually simple argument resolve problem using regret bound ot fpl adversarial multiarmed bandit problem shown bound hold common fpl variant using observation designated exploration round using observation allows stronger bound ot matching best bound known far essentially known lower bound adversarial bandit surprisingly variant even need explicit exploration selfstabilizing however sampling probability either externally provided approximated sufficient accuracy using ot log sample step
cs.LG,naive bayes simple bayesian classifier strong independence assumption among attribute classifier desipte strong independence assumption often performs well practice believed relaxing independence assumption naive bayes classifier may improve classification accuracy resulting structure finding optimal unconstrained bayesian network reasonable scoring measure nphard problem possible learn polynomial time optimal network obeying various structural restriction several author examined possibility adding augmenting arc attribute naive bayes classifier friedman geiger goldszmidt define tan structure augmenting arc form tree attribute present polynomial time algorithm learns optimal tan respect mdl score keogh pazzani define augmented bayes network augmenting arc form forest attribute collection tree hence relaxation stuctural restriction tan present heuristic search method learning good though optimal augmenting arc set author however evaluate learned structure term observed misclassification error scoring metric mdl paper present simple polynomial time greedy algorithm learning optimal augmented bayes network respect mdl score
cs.LG,consider problem learning union rectangle domain bn uniform distribution membership query learning setting b n large obtain polyn log btime algorithm following class polyn log bway majority ofraclogn log b log logn log bdimensional rectangle union polylogn log b many ofraclog n log b log logn log b log log log n log bdimensional rectangle polyn log bway majority polyn log bor disjoint ofraclogn log b log logn log bdimensional rectangle main algorithmic tool extension jackson boosting fourierbased harmonic sieve algorithm jackson domain bn building work akavia goldwasser safra ingredient used obtain result stated technique exact learning beimel kushilevitz idea recent work learning augmented ac circuit jackson klivans servedio representing boolean function threshold parity klivans servedio
cs.LG,consider problem online prediction realvalued label assumed bounded absolute value known constant new object known labeled object prediction algorithm performance measured squared deviation prediction actual label stochastic assumption made way label object generated instead given benchmark class prediction rule hoped produce good prediction show wide range infinitedimensional benchmark class one construct prediction algorithm whose cumulative loss first n example exceed cumulative loss prediction rule class plus osqrtn main difference known result impose upper bound norm considered prediction rule achieve optimal leading term excess loss algorithm benchmark class universal dense class continuous function compact set provides online nonstochastic analogue universally consistent prediction nonparametric statistic use two proof technique one based aggregating algorithm recently developed method defensive forecasting
cs.LG,problem finding optimum using noisy evaluation smooth cost function arises many context including economics business medicine experiment design foraging theory derive asymptotic bound e xt x osqrtt rate convergence sequence x x generated unbiased feedback process observing noisy evaluation unknown quadratic function maximised x bound tight proof lead simple algorithm meet establish bound total regret e sumit xi x osqrtt bound may impose practical limitation agent performance oeps query made query converge x eps accuracy
cs.LG,key data preparation step text mining term extraction selects term collocation word attached specific concept paper task extracting relevant collocation achieved supervised learning algorithm exploiting collocation manually labelled relevantirrelevant candidate term described along standard statistical criterion measure example evolutionary learning algorithm termed roger based optimization area roc curve criterion extract order candidate term robustness approach demonstrated two realworld domain application considering different domain biology human resource different language english french
cs.LG,consider problem online prediction competitive benchmark class continuous highly irregular prediction rule known benchmark class reproducing kernel hilbert space exists prediction algorithm whose average loss first n example exceed average loss prediction rule class plus regret term element natural benchmark class however irregular class hilbert space paper develop banachspace method construct prediction algorithm regret term onp p infty p reflects degree benchmark class fails hilbert space
cs.LG,fitness function based test case common genetic programming gp process assimilated learning task inference model limited number sample paper investigation two method improve generalization gpbased learning selection bestofrun individual using three data set methodology application parsimony pressure order reduce complexity solution result using gp binary classification setup show accuracy test set preserved le variance compared baseline result mean tree size obtained tested method significantly reduced
cs.LG,suggested insert test matrix correct response response refusal negative corrective element incorrect response classical test theory approach test score examinee item calculated traditionally sum matrix element organized row column correlation coefficient estimated using correction coefficient item response theory approach examinee item logits estimated using maximum likelihood method probability matrix element
cs.LG,given finite set word wwn independently drawn according fixed unknown distribution law p called stochastic language usual goal grammatical inference infer estimate p class probabilistic model probabilistic automaton pa study class rational stochastic language consists stochastic language generated multiplicity automaton strictly includes class stochastic language generated pa rational stochastic language minimal normal representation may concise whose parameter efficiently estimated stochastic sample design efficient inference algorithm dees aim building minimal normal representation target despite fact recursively enumerable class computes exactly set rational stochastic language q show dees strongly identifies ti set limit study intermediary output dees show compute rational series converge absolutely one used provide stochastic language closely estimate target
cs.LG,consider agent interacting environment cycle every interaction cycle agent rewarded performance compare average reward u cycle average value future discounted reward v cycle k infinity discounted value consider essentially arbitrary nongeometric discount sequence arbitrary reward sequence nonmdp environment show asymptotically u minfinity v kinfinity equal provided limit exist effective horizon grows linearly k faster existence limit u implies limit v exists conversely effective horizon grows linearly k slower existence limit v implies limit u exists
cs.LG,suppose given two probability measure set oneway infinite finitealphabet sequence consider question one measure predicts conditional probability converge certain sense one measure chosen generate sequence question may considered refinement problem sequence prediction general formulation given class probability measure exist measure predicts measure class address problem find condition local absolute continuity sufficient prediction generalize several different notion known sufficient prediction also formulate open question outline direction finding condition class measure prediction possible
cs.LG,prediction complex notion different predictor people computer program probabilistic theory pursue different goal paper review popular kind prediction argue theory competitive online learning benefit kind prediction foreign
cs.LG,standard approach pattern classification estimate distribution label class apply bayes classifier estimate distribution order classify unlabeled example one might expect better estimate label class distribution better resulting classifier paper make observation precise identifying risk bound classifier term quality estimate label class distribution show pac learnability relates estimate distribution pac guarantee l distance true distribution bound increase negative log likelihood risk term pac bound kldivergence give inefficient generalpurpose smoothing method converting estimated distribution good l metric distribution good kldivergence
cs.LG,paper introduce class stationary prediction strategy construct prediction algorithm asymptotically performs well best continuous stationary strategy make mild compactness assumption stochastic assumption environment particular assumption stationarity made environment stationarity considered strategy mean depend explicitly time argue natural consider stationary strategy even highly nonstationary environment
cs.LG,probabilistic grammatical inference usual goal infer good approximation unknown distribution p called stochastic language estimate p stand class probabilistic model probabilistic automaton pa paper focus probabilistic model based multiplicity automaton stochastic language generated called rational stochastic language strictly include stochastic language generated pa also admit concise canonical representation despite fact class recursively enumerable efficiently identifiable limit using algorithm dees introduced author previous paper however identification proper convergence algorithm dees produce define stochastic language nevertheless possible use define stochastic language show belong broader class rational series call pseudostochastic rational language aim paper twofold first provide theoretical study pseudostochastic rational language language output dees showing example class decidable within polynomial time second carried lot experiment order compare dees classical inference algorithm alergia mdi show dees outperforms case
cs.LG,investigate concept learning incomplete example first purpose discus extent logical learning setting modified order cope data incompleteness precisely interested extending learning interpretation setting introduced l de raedt extends relational representation classical propositional attributevalue concept learning example framework inspired idea presented h hirsh work extending version space inductive paradigm incomplete data h hirsh proposes slightly modify notion solution dealing incomplete example solution hypothesis compatible piece information concerning example identify two main class incompleteness first uncertainty deal state knowledge concerning example second generalization abstraction deal part description example sufficient learning purpose two main source incompleteness mixed part useful information known discus general learning setting referred learning possibility formalizes idea present specific learning setting referred assumptionbased learning cope example uncertainty reduced considering contextual information outside proper description example assumptionbased learning illustrated recent work concerning prediction consensus secondary structure common set rna sequence
cs.LG,present theory boosting probabilistic classifier place situation user provides stopping parameter probabilistic weak learnerclassifier compare three type boosting algorithm probabilistic adaboost decision tree tree tree tree call matryoshka nested tree embedded tree recursive tree also appropriate name algorithm one contribution contribution theoretical analysis algorithm give training error bound analysis suggests matryoshka leverage probabilistic weak classifier efficiently simple decision tree
cs.LG,start simple asymptotic result problem online regression quadratic loss function class continuous limitedmemory prediction strategy admits leading prediction strategy asymptotically performs least well continuous limitedmemory strategy also satisfies property excess loss continuous limitedmemory strategy determined closely imitates leading strategy specifically class prediction strategy constituting reproducing kernel hilbert space construct leading strategy sense loss prediction strategy whose norm large determined closely imitates leading strategy result extended loss function given bregman divergence strictly proper scoring rule
cs.LG,assuming loss function convex prediction construct prediction strategy universal class markov prediction strategy necessarily continuous allowing randomization remove requirement convexity
cs.LG,present basic notion gold learnability limit paradigm first presented formalization cognitive process native speaker get grasp underlying grammar hisher native language exposed well formed sentence generated grammar present lambek grammar formalism issued categorial grammar although expressive needed full formalization natural language particularly suited easily implement natural interface syntax semantics last part work present learnability result rigid lambek grammar structured example
cs.LG,approach classification problem machine learning based building local classification rule developed local rule considered projection global classification rule event want classify massive global optimization algorithm used optimization quality criterion algorithm polynomial complexity typical case used find highquality local rule distinctive feature algorithm integration attribute level selection ordered attribute rule searching original conflicting rule resolution strategy algorithm practical tested number data set uci repository comparison predicting technique presented
cs.LG,competitive online prediction also known universal prediction individual sequence strand learning theory avoiding making stochastic assumption way observation generated predictor goal compete benchmark class prediction rule often proper banach function space metric entropy provides unifying framework competitive online prediction numerous known upper bound metric entropy various compact set function space readily imply bound performance online prediction strategy paper discus strength limitation direct approach competitive online prediction via metric entropy including comparison approach
cs.LG,propose analyze new vantage point learning mixture gaussians namely pacstyle model learning probability distribution introduced kearns et al task construct hypothesis mixture gaussians statistically indistinguishable actual mixture generating data specifically kldivergence epsilon scenario give polynepsilontime algorithm learns class mixture constant number axisaligned gaussians ndimensional euclidean space algorithm make assumption separation mean gaussians dependence minimum mixing weight contrast learning result known clustering model assumption unavoidable algorithm relies method moment subalgorithm developed previous work author focs discrete mixturelearning problem
cs.LG,recent advance machine learning make possible design efficient prediction algorithm data set huge number parameter paper describes new technique hedging prediction output many algorithm including support vector machine kernel ridge regression kernel nearest neighbour many stateoftheart method hedged prediction label new object include quantitative measure accuracy reliability measure provably valid assumption randomness traditional machine learning object label assumed generated independently probability distribution particular becomes possible control statistical fluctuation number erroneous prediction selecting suitable confidence level validity achieved automatically remaining goal hedged prediction efficiency taking full account new object feature available information produce accurate prediction possible done successfully using powerful machinery modern machine learning
cs.LG,paper address issue policy evaluation markov decision process using linear function approximation provides unified view algorithm tdlambda lstdlambda ilstd residualgradient td asserted consist minimizing gradient function differ form function mean minimizing two new scheme introduced framework fullgradient td us generalization principle introduced ilstd egd td reduces gradient successive equigradient descent three algorithm form new intermediate family interesting property making much better use sample td keeping gradient descent scheme useful complexity issue optimistic policy iteration
cs.LG,bandit based method tree search recently gained popularity applied huge tree eg game go gelly et al uct algorithm kocsis szepesvari tree search method based upper confidence bound ucb auer et al believed adapt locally effective smoothness tree however show uct optimistic case leading regret oexpexpd depth tree propose alternative bandit algorithm tree search first modification uct using confidence sequence scale exponentially horizon depth proven regret od sqrtn adapt possible smoothness tree analyze flatucb performed leaf provide finite regret bound high probability introduce ucbbased bandit algorithm smooth tree take account actual smoothness reward performing efficient cut suboptimal branch high confidence finally present incremental tree search version applies full tree big possibly infinite entirely represented show high probability essentially optimal branch indefinitely developed illustrate method global optimization problem lipschitz function given noisy data
cs.LG,propose axiomatic approach concept intrinsic dimension dataset based viewpoint geometry highdimensional structure first axiom postulate high value dimension indicative presence curse dimensionality certain precise mathematical sense second axiom requires dimension depend smoothly distance datasets dimension dataset approximating principal manifold would close third axiom normalization condition dimension euclidean nsphere sn thetan give example dimension function satisfying axiom even though general computationally unfeasible discus computationally cheap function satisfying axiom intrinsic dimensionality chavez et al
cs.LG,paper uncovers explores close relationship monte carlo optimization parametrized integral mco parametric machinelearning pl blackbox oraclebased optimization bo make four contribution first prove mco mathematically identical broad class pl problem identity potentially provides new application domain broadly applicable pl technique mco second introduce immediate sampling new version probability collective pc algorithm blackbox optimization immediate sampling transforms original bo problem mco problem accordingly combining first two contribution apply pl technique bo third contribution validate way improving bo demonstrating crossvalidation bagging improve immediate sampling finally conventional mc mco procedure ignore relationship sample point location associated value integrand value integrand location considered demonstrate one exploit sample location information using pl technique example forming fit sample location associated value integrand provides additional way apply pl technique improve mco
cs.LG,introduce framework filtering feature employ hilbertschmidt independence criterion hsic measure dependence feature label key idea good feature maximise dependence feature selection various supervised learning problem including classification regression unified framework solution approximated using backwardelimination algorithm demonstrate usefulness method artificial real world datasets
cs.LG,speaker identification powerful noninvasive inexpensive biometric technique recognition accuracy however deteriorates noise level affect specific band frequency paper present subband based speaker identification intends improve live testing performance frequency subband processed classified independently also compare linear nonlinear merging technique subbands recognizer support vector machine gaussian mixture model nonlinear merging technique investigated result showed subband based method used linear merging technique enormously improved performance speaker identification performance wideband recognizers tested live live testing improvement achieved
cs.LG,bound risk play crucial role statistical learning theory usually involve capacity measure model studied vc dimension one extension classification vc dimension exist model taking value q r introduce generalization appropriate missing case one model value rq provides u new guaranteed risk msvms appears superior existing one
cs.LG,consider leastsquare regression problem regularization block norm ie sum euclidean norm space dimension larger one problem referred group lasso extends usual regularization norm space dimension one commonly referred lasso paper study asymptotic model consistency group lasso derive necessary sufficient condition consistency group lasso practical assumption model misspecification linear predictor euclidean norm replaced function reproducing kernel hilbert norm problem usually referred multiple kernel learning commonly used learning heterogeneous data source non linear variable selection using tool functional analysis particular covariance operator extend consistency result infinite dimensional case also propose adaptive scheme obtain consistent model estimate even necessary condition required non adaptive scheme satisfied
cs.LG,supervised learning deal inference distribution output label space cy conditioned point observation space cx given training dataset pair cx time cy however lot application interest acquisition large amount observation easy process generating label timeconsuming costly one way deal problem em active learning point labelled selected aim creating model better performance model trained equal number randomly sampled point paper instead propose deal labelling cost directly learning goal defined minimisation cost function expected model performance total cost label used allows development general strategy specific algorithm optimal stopping expected cost dictate whether label acquisition continue b empirical evaluation cost used performance metric given combination inference stopping sampling method though main focus paper optimal stopping also aim provide background development discussion related field active learning
cs.LG,method defensive forecasting applied problem prediction expert advice binary outcome turn defensive forecasting competitive aggregating algorithm also handle case secondguessing expert whose advice depends learner prediction paper assumes dependence learner prediction continuous
cs.LG,defensive forecasting method transforming law probability stated gametheoretic term strategy sceptic forecasting algorithm two known variety defensive forecasting continuous sceptic move assumed depend forecast semicontinuous manner produce deterministic forecast randomized dependence sceptic move forecast arbitrary forecaster move allowed randomized note show randomized variety obtained continuous variety smearing sceptic move make continuous
cs.LG,purpose note show method maximum entropy mean mem may used improve parametric estimation measurement corrupted large level noise method developed context concrete example estimation parameter exponential distribution compare performance method bayesian maximum likelihood approach
cs.LG,show brier game prediction mixable find optimal learning rate substitution function resulting prediction algorithm applied predict result football tennis match theoretical performance guarantee turn rather tight data set especially case extensive tennis data
cs.LG,regularization sum singular value also referred trace norm popular technique estimating low rank rectangular matrix paper extend consistency result lasso provide necessary sufficient condition rank consistency trace norm minimization square loss also provide adaptive version rank consistent even necessary condition non adaptive version fulfilled
cs.LG,recent spectral clustering method propular powerful technique data clustering method need solve eigenproblem whose computational complexity n number data sample paper noneigenproblem based clustering method proposed deal clustering problem performance comparable spectral clustering algorithm efficient computational complexity show transitive distance observed property called kmeans duality algorithm used handle data set complex cluster shape multiscale cluster noise moreover parameter except number cluster need set algorithm
cs.LG,covariance categorical variable defined using regular simplex expression category method follows variance definition gini give covariance solution simultaneous equation calculated result give reasonable value test data method principal component analysis rspca also proposed using regular simplex expression allows easy interpretation principal component proposed method apply variable selection problem categorical data uscensus data proposed method give appropriate criterion variable selection problem categorical
cs.LG,classification problem described joint density pomegax model pomegaeqomegaxx bayesian similarity measure shown optimal similarity measure nearest neighbor classification paper analyzes demonstrates several additional property conditional distribution paper first show reconstruct class label class posterior distribution pomegax given pomegaeqomegaxx give procedure recovering class label give asymptotically bayesoptimal classification procedure also show given optimal similarity measure construct classifier outperforms nearest neighbor classifier achieves bayesoptimal classification rate paper analyzes bayesian similarity framework classifier face number related classification task multitask learning illustrates reconstruction class posterior distribution possible general finally paper identifies distinct class classification problem using pomegaeqomegaxx show using pomegaeqomegaxx solve problem bayes optimal solution
cs.LG,learning machine hierarchical structure hidden variable singular statistical model nonidentifiable fisher information matrix singular singular statistical model neither bayes posteriori distribution converges normal distribution maximum likelihood estimator satisfies asymptotic normality main reason difficult predict generalization performance trained state paper study four error bayes generalization error bayes training error gibbs generalization error gibbs training error prove mathematical relation among error formula proved paper equation state statistical estimation hold true distribution parametric model priori distribution also show bayes gibbs generalization error estimated bayes gibbs training error propose widely applicable information criterion applied regular singular statistical model
cs.LG,consider problem choosing density estimate set distribution f minimizing ldistance unknown distribution devroye lugosi devroye lugosi analyze two algorithm problem scheffe tournament winner minimum distance estimate scheffe tournament estimate requires fewer computation minimum distance estimate strictly weaker guarantee latter focus computational aspect density estimation present two algorithm guarantee minimum distance estimate first one modification minimum distance estimate us number quadratic f computation scheffe tournament second one called efficient minimum lossweight estimate us linear number computation assuming f preprocessed also give example showing guarantee algorithm improved explore randomized algorithm density estimation
cs.LG,point cloud set point two three dimension kernel method learning set point yet dealt specific geometrical invariance practical constraint associated point cloud computer vision graphic paper present extension graph kernel point cloud allow use kernel method ob jects shape line drawing threedimensional point cloud order design rich numerically efficient kernel free parameter possible use kernel covariance matrix factorization graphical model derive polynomial time dynamic programming recursion present application recognition handwritten digit chinese character training example
cs.LG,crossentropy method simple efficient method global optimization paper provide two online variant basic cem together proof convergence
cs.LG,prove optimal assignment kernel proposed recently attempt embed labeled graph generally tuples basic data hilbert space fact always positive definite
cs.LG,given r group numerical variable x xr assume group result one underlying latent variable latent variable bound together linear equation system moreover assume explanatory latent variable may interact pairwise one equation basically consider pls path modelling algorithm estimate latent variable model coefficient new external estimation scheme proposed draw latent variable towards strong group structure flexible way new internal estimation scheme proposed enable plspm make good use variable group complementarity deal interaction application example given
cs.LG,present general approach collaborative filtering cf using spectral regularization learn linear operator user object rate recent lowrank type matrix completion approach cf shown special case however unlike existing regularization based cf method approach used also incorporate information attribute user object limitation existing regularization based cf method provide novel representer theorem use develop new estimation method provide learning algorithm based lowrank decomposition test standard cf dataset experiment indicate advantage generalizing existing regularization based cf method incorporate related information user object finally show certain multitask learning method also seen special case proposed approach
cs.LG,study problem learning kjuntas given access example drawn number different product distribution thus wish learn function f n depends k unknown coordinate best known algorithm general problem learning kjunta require running time nk polynk show given access k different product distribution bias separated gamma function may learned time polynkgammak generally given access k different product distribution function may learned time nkt polynkgammak technique involve novel result fourier analysis relating fourier expansion respect different bias generalization russos formula
cs.LG,use computational intelligence technique classification used numerous application paper compare use multi layer perceptron neural network new relational network classifying hiv status woman antenatal clinic paper discus architecture relational network merit compared neural network computational intelligence classifier result gathered study indicate comparable classification accuracy well revealed relationship data feature classification data much higher classification accuracy recommended future research area hiv classification well missing data estimation
cs.LG,paper aim showcase measure structural diversity ensemble classifier map relationship structural diversity accuracy structural diversity induced different architecture structure classifier genetical algorithm ga used derive relationship diversity classification accuracy evolving classifier picking classifier ensemble classifier found ensemble became diverse accuracy improved however certain diversity measure accuracy began drop kohaviwolpert variance method used measure diversity ensemble method voting used aggregate result classifier lowest error observed diversity measure mean square error taking maximum diversity measured parameter varied number hidden node learning rate activation function
cs.LG,using support vector machine requires set two type hyperparameters soft margin parameter c parameter kernel perform model selection task method choice crossvalidation leaveoneout variant known produce estimator generalization error almost unbiased major drawback rest time requirement overcome difficulty several upper bound leaveoneout error pattern recognition svm derived among bound popular one probably radiusmargin bound applies hard margin pattern recognition svm extension norm svm report introduce quadratic loss msvm msvm direct extension norm svm multiclass case machine generalized radiusmargin bound established
cs.LG,article considers constrained ell minimization method recovery high dimensional sparse signal three setting noiseless bounded error gaussian noise unified elementary treatment given noise setting two ell minimization method dantzig selector ell minimization ell constraint result paper improve existing result literature weakening condition tightening error bound improvement condition show signal larger support recovered accurately paper also establishes connection restricted isometry property mutual incoherence property result candes romberg tao donoho elad temlyakov extended
cs.LG,identify classical perceptron algorithm margin member broader family large margin classifier collectively call margitron margitron despite sharing update rule perceptron shown incremental setting converge finite number update solution possessing desirable fraction maximum margin experiment comparing margitron decomposition svms task involving linear kernel norm soft margin also reported
cs.LG,paper present theoretical analysis sample selection bias correction sample bias correction technique commonly used machine learning consists reweighting cost error training point biased sample closely reflect unbiased distribution relies weight derived various estimation technique based finite sample analyze effect error estimation accuracy hypothesis returned learning algorithm two estimation technique clusterbased estimation technique kernel mean matching also report result sample bias correction experiment several data set using technique analysis based novel concept distributional stability generalizes existing concept pointbased stability much work proof technique used analyze importance weighting technique effect accuracy using distributionally stable algorithm
cs.LG,article describes approach designing distributed modular neural classifier approach introduces new hierarchical clustering enables one determine reliable region representation space exploiting supervised information multilayer perceptron associated detected cluster charged recognizing element associated cluster rejecting others obtained global classifier comprised set cooperating neural network completed knearest neighbor classifier charged treating element rejected neural network experimental result handwritten digit recognition problem comparison neural statistical nonmodular classifier given
cs.LG,nous presentons dans cette contribution une approche la fois symbolique et probabiliste permettant dextraire linformation sur la segmentation du signal de parole partir dinformation prosodique nous utilisons pour ce faire de grammaires probabilistes possedant une structure hierarchique minimale la phase de construction de grammaires ainsi que leur pouvoir de prediction sont evalues qualitativement ainsi que quantitativement methodologically oriented present work sketch approach prosodic information retrieval speech segmentation based symbolic probabilistic information recourse probabilistic grammar within implement minimal hierarchical structure stage probabilistic grammar building testing prediction explored quantitatively qualitatively evaluated
cs.LG,statistical learning theory chiefly study restricted hypothesis class particularly finite vapnikchervonenkis vc dimension fundamental quantity interest sample complexity number sample required learn specified level accuracy consider learning set computable labeling function since vcdimension infinite priori uniform bound number sample impossible let learning algorithm decide seen sufficient sample learned first show learning setting indeed possible develop learning algorithm show however bounding sample complexity independently distribution impossible notably impossibility entirely due requirement learning algorithm computable due statistical nature problem
cs.LG,prove class function gn depend unknown subset kn variable socalled kjuntas agnostically learnable random walk time polynomial n k epsilonk logdelta word algorithm claimed running time given epsilon delta access random walk n labeled arbitrary function fn find probability least delta kjunta optfepsilonclose f optf denotes distance closest kjunta f
cs.LG,method stable random projection tool efficiently computing lalpha distance using low memory alpha leq tuning parameter method boil statistical estimation task various estimator proposed based geometric mean harmonic mean fractional power etc study proposes optimal quantile estimator whose main operation selecting considerably le expensive taking fractional power main operation previous estimator experiment report optimal quantile estimator nearly one order magnitude computationally efficient previous estimator largescale learning task storing computing pairwise distance serious bottleneck estimator desirable addition computational advantage optimal quantile estimator exhibit nice theoretical property accurate previous estimator alpha derive theoretical error bound establish explicit ie hidden constant sample complexity bound
cs.LG,application machine learning data mining require computing pairwise lp distance data matrix massive highdimensional data computing pairwise distance infeasible fact even storing pairwise distance memory may also infeasible paper proposes simple method p first decompose lp p even distance sum marginal norm p inner product different order apply normal subgaussian random projection approximate resultant inner product assuming marginal norm computed exactly linear scan propose two strategy applying random projection basic projection strategy requires one projection matrix difficult analyze alternative projection strategy requires p projection matrix theoretical analysis much easier term accuracy least p basic strategy always accurate alternative strategy data nonnegative common reality
cs.LG,present unified framework study graph kernel special case include random walk graph kernel citepgaeflawroborongschvisetal marginalized graph kernel citepkastsuinokastsuinomahuedakuperetal geometric kernel graph citepgaertner extension linear algebra reproducing kernel hilbert space rkhs reduction sylvester equation construct algorithm improves time complexity kernel computation graph sparse conjugate gradient solver fixedpoint iteration bring algorithm subcubic domain experiment graph bioinformatics application domain show often thousand time faster previous approach explore connection diffusion kernel citepkonlaf regularization graph citepsmokon graph kernel use connection propose new graph kernel finally show rational kernel citepcorhafmohcorhafmohcorhafmoh specialized graph reduce random walk graph kernel
cs.LG,study probability distribution free algebra tree probability distribution seen particular formal power tree series berstel et al esik et al ie mapping tree semiring k widely studied class tree series class rational recognizable tree series defined either algebraic way mean multiplicity tree automaton argue algebraic representation convenient model probability distribution free algebra tree first string case algebraic representation allows design learning algorithm whole class probability distribution defined rational tree series note learning algorithm rational tree series correspond learning algorithm weighted tree automaton structure weight learned second algebraic representation easily extended deal unranked tree like xml tree symbol may unbounded number child property particularly relevant application nondeterministic automaton required inference problem relevant recall hidden markov model equivalent nondeterministic string automaton nowadays application web information extraction web service document processing consider unranked tree
cs.LG,present novel graphical framework modeling nonnegative sequential data hierarchical structure model corresponds network coupled nonnegative matrix factorization nmf module refer positive factor network pfn data model linear subject nonnegativity constraint observation data consisting additive combination individually representable observation also representable network desirable property modeling problem computational auditory scene analysis since distinct sound source environment often wellmodeled combining additively corresponding magnitude spectrogram propose inference learning algorithm leverage existing nmf algorithm straightforward implement present target tracking example provide result synthetic observation data serve illustrate interesting property pfns motivate potential usefulness application music transcription source separation speech recognition show target process characterized hierarchical state transition model represented pfn result illustrate pfn defined term single target observation used effectively track state multiple simultaneous target result show quality inferred target state degrades gradually observation noise increased also present result example meaningful hierarchical feature extracted spectrogram hierarchical representation could useful music transcription source separation application also propose network language modeling
cs.LG,consider general class regularization method learn vector parameter basis linear measurement well known regularizer nondecreasing function inner product learned vector linear combination input data result known em representer theorem basis kernelbased method machine learning paper prove necessity condition thereby completing characterization kernel method based regularization extend analysis regularization method learn matrix problem motivated application multitask learning context study general representer theorem hold larger class regularizers provide necessary sufficient condition class matrix regularizers highlight concrete example practical importance analysis us basic principle matrix theory especially useful notion matrix nondecreasing function
cs.LG,multitask learning several related task considered simultaneously hope appropriate sharing information across task task may benefit others context learning linear function supervised classification regression achieved including priori information weight vector associated task expected related paper assume task clustered group unknown beforehand task within group similar weight vector design new spectral norm encodes priori assumption without prior knowledge partition task group resulting new convex optimization formulation multitask learning show simulation synthetic example iedb mhci binding dataset approach outperforms wellknown convex method multitask learning well related non convex method dedicated problem
cs.LG,consider task learning classifier feature space mathcalx set class mathcaly feature partitioned classconditionally independent feature set mathcalx mathcalx show surprising fact classconditional independence used represent original learning task term learning classifier mathcalx mathcalx learning classconditional distribution feature set mathcalx fact exploited semisupervised learning former task accomplished purely unlabeled sample present experimental evaluation idea two real world application
cs.LG,maximum variance unfolding mvu variant successful embedding datamanifolds lower dimensional space often revealing true intrinsic dimension paper show also incorporate supervised class information mvulike method without breaking convexity call method isometric separation map show resulting kernel matrix used binarymulticlass support vector machinelike method semisupervised transductive framework also show method always find kernel matrix linearly separate training data exactly without projecting infinite dimensional space traditional svms choose kernel hope data become linearly separable kernel space paper show hyperplane chosen adhoc kernel trained data always linearly separable comparison large margin svms show comparable performance
cs.LG,paper expand shannon definition entropy new form entropy allows integration information different random event shannon notion entropy special case general definition entropy define probability using socalled performance function de facto exponential distribution assuming general notion entropy reflects true uncertainty probabilistic event understand perceived uncertainty differs claim perception result two opposing force similar two famous antagonist chinese philosophy yin yang based idea show perceived uncertainty match true uncertainty point determined golden ratio demonstrate wellknown sigmoid function typically employ artificial neural network nonlinear threshold function describes actual performance furthermore provide motivation time dilation einstein special relativity basically claiming although time dilation conforms perception correspond reality end paper show apply theoretical framework practical application present recognition rate pattern recognition problem also propose network architecture take advantage general entropy solve complex decision problem
cs.LG,generalization bound learning theory based measure complexity hypothesis class used independently algorithm contrast notion algorithmic stability used derive tight generalization bound tailored specific learning algorithm exploiting particular property however much learning theory existing stability analysis bound apply scenario sample independently identically distributed many machine learning application however assumption hold observation received learning algorithm often inherent temporal dependence paper study scenario observation drawn stationary phimixing betamixing sequence widely adopted assumption study noniid process implies dependence observation weakening time prove novel distinct stabilitybased generalization bound stationary phimixing betamixing sequence bound strictly generalize bound given iid case apply stable learning algorithm thereby extending use stabilitybounds noniid scenario also illustrate application phimixing generalization bound general class learning algorithm including support vector regression kernel ridge regression support vector machine many kernel regularizationbased relative entropybased regularization algorithm novel bound thus viewed first theoretical basis use algorithm noniid scenario
cs.LG,ensemble classification emerging approach land cover mapping whereby final classification output result consensus classifier intuitively ensemble system consist base classifier diverse ie classifier whose decision boundary err differently paper ensemble feature selection used impose diversity ensemble feature constituent base classifier ensemble created exhaustive search algorithm using different separability index ensemble classification accuracy derived well diversity measure purported give measure inensemble diversity correlation ensemble classification accuracy diversity measure determined establish interplay two variable finding paper diversity measure currently formulated provide adequate mean upon constitute ensemble land cover mapping
cs.LG,enormous success made quantum algorithm last decade paper combine quantum random walk qrw problem data clustering develop two clustering algorithm based one dimensional qrw probability distribution position induced qrw algorithm investigated also indicates possibility obtaining better result consequently experimental result demonstrated data point datasets clustered reasonably efficiently clustering algorithm fast rate convergence moreover comparison algorithm also provides indication effectiveness proposed approach
cs.LG,present convex formulation dictionary learning sparse signal decomposition convexity obtained replacing usual explicit upper bound dictionary size convex rankreducing term similar trace norm particular formulation introduces explicit tradeoff size sparsity decomposition rectangular matrix using large set synthetic example compare estimation ability convex nonconvex approach showing convex formulation single local minimum may lead case performance inferior local minimum nonconvex formulation
cs.LG,introduce simple computationally trivial method binary classification based evaluation potential function demonstrate despite conceptual computational simplicity method performance match exceed standard support vector machine method
q-bio.NC,study mechanism responsible synchronous oscillation loss synchrony physiologically relevant frequency hz network heterogeneous inhibitory neuron focus factor determine level synchrony frequency network response well effect mild heterogeneity network dynamic mild heterogeneity synchrony never perfect relatively fragile addition effect inhibition complex mildly heterogeneous network homogeneous one former synchrony broken two distinct way depending ratio synaptic decay time period repetitive action potential taust determined either network single selfinhibiting neuron taust corresponding large applied current small synaptic strength large synaptic decay time effect inhibition largely tonic heterogeneous neuron spike relatively independently taust synchrony break faster cell begin suppress le excitable neighbor cell fire remain nearly synchronous show numerically behavior mildly heterogeneous network related behavior single selfinhibiting cell studied analytically
q-bio.NC,analyze control frequency synchronized inhibitory neuronal network analysis done reduced membrane model biophysicallybased synaptic influence argue reduced model quantitatively capture frequency behavior larger class neuronal model show different parameter regime network frequency depends different way intrinsic synaptic time constant one portion parameter space called phasic network period proportional synaptic decay time result discussed connection previous work author showed mildly heterogeneous network synchrony break coherence preserved much system phasic regime regime result imply mildly heterogeneous network existence coherent rhythm implies linear dependence network period synaptic decay time much weaker dependence drive cell give experimental evidence conclusion
q-bio.NC,would like know whether statistic neuronal response vary across cortical area examined stimuluselicited spike count response distribution v cortex awake monkey area distribution spike count stimulus welldescribed gaussian log variance spike count linearly related log mean spike count two significant difference response characteristic found range spike count slope logvariance v logmean regression larger v however neuron two area transmitted approximately amount information stimulus channel capacity maximum possible transmitted information given noise response result suggest neuron v use variable signal larger dynamic range neuron use le variable signal smaller dynamic range two coding strategy approximately effective transmitting information
q-bio.NC,review recent development measurement dynamic response property auditory cortical neuron broadband sound closely related perception timbre emphasis method characterizes spectrotemporal property single neuron dynamic broadband sound akin drifting grating used vision method treat spectral temporal aspect response equal footing
q-bio.NC,analyze synaptic transmission informationtheoretic perspective derive closedform expression lowerbounds capacity simple model cortical synapse two explicit coding paradigm signal estimation paradigm assume signal encoded mean firing rate poisson neuron performance optimal linear estimator signal provides lower bound capacity signal estimation signal detection paradigm presence absence signal detected performance optimal spike detector allows u compute lower bound capacity signal detection find single synapsis empirically measured parameter value transmit information poorly significant improvement achieved small amount redundancy
q-bio.NC,study insect olfactory processing indicate odor represented rich spatiotemporal pattern neural activity pattern difficult predict priori yet stimulus specific reliable upon repeated stimulation input formulate theoretical framework interpret experimental result propose paradigm dynamic competition input odor represented internally competing neural assembly pattern result dynamical motion within network involve winner among competing possibility model produce spatiotemporal pattern strong resemblance observed experimentally posse many general feature one desire pattern classifier large information capacity reliability specific response specific input reduced sensitivity initial condition influence noise form neural processing may thus describe organizational principle neural information processing sensory system go well beyond observation insect olfactory processing motivated development
q-bio.NC,number cortical structure reported elevated single unit firing rate sustained throughout memory period working memory task nervous system form maintains memory unknown reverberating neuronal network activity thought important studied temporal structure single unit su activity simultaneously recorded local field potential lfp activity area lip inferior parietal lobe two awake macaque memorysaccade task using multitaper technique spectral analysis play important role obtaining present result find elevation spectral power hz gamma frequency band memory period su lfp activity activity tuned direction saccade providing evidence temporal structure code movement plan working memory also find su lfp activity coherent memory period hz gamma band consistent relation present simple fixation finally find organized lfp activity hz frequency band may related movement execution preparatory aspect task neuronal activity could used control neural prosthesis su activity hard isolate cortical implant lfp easier acquire su activity finding rich temporal structure lfp activity related movement planning execution may accelerate development medical application
q-bio.NC,generalized languageofthought argument appropriate interacting cognitive module permit exploration disease state interact medical treatment interpenetrating feedback treatment response creates kind idiotypic hallofmirrors generating synergistic pattern efficacy treatment failure adverse reaction patient noncompliance rate distortion perspective embodies distorted image externallyimposed structured psychosocial stress u accelerating spatial social diffusion stress enmeshes dominant subordinate population linked system express increasingly unhealthy society diffusion therapeutic failure including limited drugbased treatment
q-bio.NC,animal experiment observed orientation preference op ocular dominance od column visual cortex brain show various pattern type show different visual map formation various specie due crossover behavior anisotropic system composed orientational scalar component easyplane heisenberg model predict transition boundary different pattern type anisotropy main bifurcation parameter consistent experimental observation
q-bio.NC,paper proposes approach framing answering fundamental question consciousness argues many theoretical debate consciousness debate begin misplaced meaningless part consciousness word many valid interesting definition part consciousness qua mind intelligence main focus hereis matter degree level binary variable proposes new mathematical work related functional neural network design design functional used engineering essential functional understanding intelligence outline key mathematics citing earlier work detail quantum theory relevant simple way proposed popular philosophy
q-bio.NC,question whether quantum coherent state sustain decoherence heating dissipation time scale comparable dynamical timescales brain neuron actively discussed last year positive answer question crucial particular consideration brain neuron quantum computer discussion mainly based theoretical argument present paper nonlinear statistical property ventral tegmental area vta genetically depressive limbic brain studied vivo flinders sensitive line rat fsl vta play key role generation pleasure development psychological drug addiction found fsl vta dopaminergic neuron signal exhibit multifractal property interspike frequency scale healthy vta dopaminergic neuron exhibit bursting activity high moment observed multifractal generalized dimension spectrum coincides generalized dimension spectrum calculated spectral measure quantum system socalled kicked harper model actively used model quantum chaos observation considered first experimental vivo indication favour quantum least partially nature brain neuron activity
q-bio.NC,study mathematical model ocular dominance pattern odps primary visual cortex model based premise odp adaptation minimize length intracortical wiring thus attempt understand existing odps solving wire length minimization problem divide neuron two class left righteye dominated find segregation neuron monocular region reduces wire length number connection neuron class intraocular differs number interocular connection shape region depends relative fraction neuron two class find class almost equally represented optimal odp consists interdigitating stripe one class le numerous optimal odp consists patch le abundant class surrounded neuron class predict transition stripe patch occurs fraction neuron dominated underrepresented eye prediction agrees data macaque cebu monkey also study dependence periodicity odp parameter model
q-bio.NC,two rate code model reconstruction network model control model hippocampalentorhinal loop merged hippocampalentorhinal loop play double role unified model part reconstruction network controller double role turn bottomup information flow topdown control like signal role bottomup filtering information maximization noise filtering temporal integration prediction whereas role topdown filtering emphasizing ie highlighting paving way well context based pattern completion joined model control task performed cortical area whereas reconstruction network found cortical area controller highly nonlinear reconstruction network almost linear architecture optimized noise estimation noise filtering conjecture reconstruction network model longterm memory visual stream linear feedback connection neocortical area reinforced joined model falsifying prediction presented recent experimental support connection attention awareness made
q-bio.NC,artificial spikebased computation inspired model computation central nervous system may present significant performance advantage traditional method specific type large scale problem paper study new model two common instance computation winnertakeall coincidence detection case fast convergence achieved independent initial condition network complexity linear number input
q-bio.NC,random walk method used calculate moment negative image equilibrium distribution synaptic weight dynamic governed spiketiming dependent plasticity stdp neural architecture model based electrosensory lateral line lobe ell mormyrid electric fish form negative image reafferent signal fish electric discharge optimize detection sensory electric field particular behavioral importance fish variance equilibrium postsynaptic potential presence noise determined variance equilibrium weight distribution recurrence relation derived moment equilibrium weight distribution arbitrary postsynaptic potential function arbitrary learning rule case homogeneous network parameter explicit closed form solution developed covariance synaptic weight postsynaptic potential distribution
q-bio.NC,artificial spikebased computation inspired model computation central nervous system may present significant performance advantage traditional method specific type large scale problem paper describes simple network architecture kwinnerstakeall softwinnertakeall computation using neural oscillator fast convergence achieved arbitrary initial condition make network particularly suitable track timevarying input
q-bio.NC,effect distraction noise parameter heterogeneity studied firing activity ensemble neuron described extended morrislecar model showing graded persisting firing aid included rm cadependent cation current although sustained activity single neuron rather robust sense activity realized even presence distraction graded frequency sustained firing vulnerable shown however graded persisting activity ensemble neuron becomes much robust distraction pooling ensemble effect coupling introduced synchronization firing ensemble neuron enhanced beneficial firing target neuron
q-bio.NC,response neural cell external stimulus follow one two pattern nonresonant neuron monotonously relax resting state excitation resonant one show subthreshold oscillation investigate subthreshold property neuron affect suprathreshold response vice versa ask distinguish type neuronal dynamic using suprathreshold spike train dynamic neuron given stochastic fitzhughnagumo morrislecar model either focus node stable fixpoint determine numerically spectral power density well interspike interval density response random noiselike signal show information type dynamic obtained power spectrum limited validity contrast interspike interval density give sensitive instrument diagnostics whether dynamic resonant nonresonant property latter value formulate fit formula use reconstruct theoretically spectral power density coincides numerically obtained spectrum underline renewal theory applicable analysis suprathreshold response even resonant neuron
q-bio.NC,cognitive frame neuropsychological research neural basis behavior conducted contains assumption brain mechanism per se fully suffice explain psychologically described phenomenon assumption stem idea brain made entirely material particle field causal mechanism must therefore formulated solely term property element one consequence stance psychological term intrinsic mentalistic andor experiential content term feeling knowing effort included primary causal factor neuropsychological research insofar property described material term deemed irrelevant causal mechanism underlying brain function however origin demand experiential reality excluded causal base theory nature known three quarter century fundamentally incorrect explained consequently scientifically unwarranted assume material factor alone principle explain causal mechanism relevant neuroscience importantly explained key quantum effect introduced brain dynamic simple practical way provides rationally coherent causally formulated physicsbased way understanding using psychological physical data derived growing set study capacity directed attention mental effort systematically alter brain function
q-bio.NC,study spike statistic neuron network dynamically balanced excitation inhibition model intended represent generic cortical column comprises randomly connected excitatory inhibitory leaky integrateandfire neuron driven excitatory input external population high connectivity permit meanfield description synaptic current treated gaussian noise mean autocorrelation function calculated selfconsistently firing statistic single model neuron within description find irregularity spike train controlled mainly strength synapsis relative difference firing threshold postfiring reset level membrane potential moderately strong synapsis find spike statistic similar observed primary visual cortex
q-bio.NC,review use mean field theory describing dynamic dense randomly connected cortical circuit simple network excitatory inhibitory leaky integrateandfire neuron show firing irregularity measured fano factor increase strength synapsis network value membrane potential reset spike generalizing model include conductancebased synapsis give insight connection firing statistic highconductance state observed experimentally visual cortex finally extension model describe orientation hypercolumn provides understanding cortical interaction sharpen orientation tuning way consistent observed firing statistic
q-bio.NC,measured response visual cortical neuron show spike time tend correlated rather exactly poisson distributed fano factor vary usually greater due tendency spike clustered burst show behavior emerges naturally balanced cortical network model random connectivity conductancebased synapsis employ mean field theory correctly colored noise describe temporal correlation neuronal activity result illuminate connection two independent experimental finding high conductance state cortical neuron natural environment variable nonpoissonian spike statistic fano factor greater
q-bio.NC,recent experiment revealed certain class inhibitory neuron cerebral cortex make synapsis onto cell body distal part dendrite target neuron mediating highly nonlinear dendritic inhibition propose novel form competitive neural network model realizes dendritic inhibition contrary conventional lateral inhibition neural network dendritic inhibition model dont always show winnertakeall behavior instead converge dont know state unknown input pattern presented derive reduced twodimensional dynamic network showing drastic shift fixed point winnertakeall state dont know state occurs accordance increase noise added stored pattern preventing misrecognition way dendritic inhibition network achieve fine pattern discrimination could one basic computation inhibitory connected recurrent neural network brain
q-bio.NC,performance hopfield neural network model numerically studied various complex network wattsstrogatz network barabasialbert network neuronal network c elegans use systematic way controlling clustering coefficient degree neuron kept unchanged find network lower clustering exhibit much better performance result discussed practical viewpoint application biological implication also suggested
q-bio.NC,melodic consonance sequence tone explained using overtone series overtone form flow line link tone melodically strength flow line determines melodic consonance hypothesis admits psychoacoustical neurophysiological interpretation fit well place theory pitch perception hypothesis used create model auditory system judge melodic consonance used algorithmically construct melodic sequence tone
q-bio.NC,present complete mean field theory balanced state simple model orientation hypercolumn theory complemented description numerical procedure solving meanfield equation quantitatively treatment determine selfconsistently firing rate firing correlation without restricted specific neuron model solve analytically derived meanfield equation numerically integrateandfire neuron several known key property orientation selective cortical neuron emerge naturally description irregular firing statistic close restricted poisson statistic almost linear gain function firing frequency function stimulus contrast neuron within network contrastinvariant tuning width neuronal firing find irregularity firing depends sensitively synaptic strength fano factor bigger stimulus orientation elicit firing also find tuning noise input current tuning external input mean input current depends external input intracortical connectivity
q-bio.NC,analyze two pulsecoupled resonateandfire neuron numerical simulation reveals antiphase state attractor model analytically explain stability antiphase state mean return map firing time propose paper resultant stability condition turn quite simple phase diagram based theory show two type antiphase state one seen coupled integrateandfire model peculiar resonateandfire model result theory coincide numerical simulation
q-bio.NC,designed toy brain written computer code simulates toy brain flexible modular hierarchical learning recognition short long term memory distributed ie central control asynchronous includes parallel series processing simulated neuron calculating internal voltage function time include simulation ion pump neuron synapsis glutamate gaba neurotransmitter delay action pulse axon dendrite used known plausible circuit real brain toy brain read book learns language using hebb mechanism finally related toy brain might occurring real brain
q-bio.NC,exhibit mathematical framework represent neural dynamic cortical level description neural dynamic columnar functional modularity named fibre bundle representation fbm method based neuroscience informatics whereas correspond conventional formula statistical physic spite complex interaction neural circuitry various cortical modification rule per model significant factor determine typical phenomenon cortical dynamic fbm representation method reveals plainly give profit building analyzing cortical dynamic model similarity formula cortical dynamic share statistical property physical system validated primary visual map apply method proposed model visual map formation addition suggestion using lateral interaction scheme paper show neural dynamic procedure treated conventional physic expression theory
q-bio.NC,recent paper cortical dynamic francis grossberg raise question visual form motion information integrated generate coherent percept moving form investigation illusory contour like kanizsa square mental construct rather stimulus retina quantify subjective impression apparent motion illusory contour formed two subsequent stimulus delay time second called interstimulus interval isi impression apparent motion due back referral later experience earlier time conscious representation model developed describes state awareness observer term time dependent schroedinger equation second order time derivative added addition requires boundary condition value solution beginning process satisfactory quantitative agreement found result model experimental result recall von neumann interpretation collapse quantum mechanical wavefunction collapse associated observer awareness question causality determinism arise latertime boundary condition touched upon
q-bio.NC,reduced model neuronal activity integrateandfire model allow description neuronal dynamic simple intuitive term easy simulate numerically present method fit integrateandfiretype model neuronal activity namely modified version spike response model detailed hodgkinhuxleytype neuron model driven stochastic spike arrival hogkinhuxley model spike arrival synapse modeled change synaptic conductance conductance spike input postsynaptic action potential predicted correct timing integrateandfiretype model modified spike response model based upon linearized theory conductancedriven integrateandfire neuron
q-bio.NC,subject perceive sensory world different stimulus elicit number neural representation subjective distance stimulus defined measuring degree similarity underlying representation example subjective distance different location space calculated activity rodent hippocampal place cell lateral septal cell distance compared real distance location number sampled neuron increase subjective distance show tendency resemble metric real space
q-bio.NC,synchronization known play vital role within many highly connected neural system olfactory system fish insect paper show one robustly effectively perform practical computation using small perturbation simple globally coupled network coupled oscillator computation performed exploiting spatiotemporal dynamic robust attracting heteroclinic network also referred winnerless competition dynamic use different cluster synchronization state encode memory state use design simple multibase counter simulation indicate give robust computational system exploiting natural dynamic system
q-bio.NC,demonstrated neural network recognize part visual image input signal gray scale photograph object consisting part output signal shape training neural network set image without supervision become able recognize boundary part
q-bio.NC,neuron noisy information processing unit conventional view information cortex carried rate neuron spike emission recent study activity propagation homogeneous network demonstrated signal transmitted millisecond fidelity model called synfire chain suggests possibility spatiotemporal coding however biologically realistic structured feedforward network generates spatially distributed input result difference spike timing pose question spatial structure network effect stability spatiotemporal spike pattern speed spike packet propagation formulating fokkerplanck equation feedforwardly coupled network mexicanhat type connectivity show stability localized spike packet existence multistable phase uniform localized spike packet stable depending initial input structure multistable phase enables u show spike pattern information determines propagation speed
q-bio.NC,two stimulus present receptive field v neuron firing rate response weakest strongest response elicited stimulus alone reynolds et al journal neuroscience attention directed towards stimulus eliciting strongest response preferred stimulus response pair increased whereas response decrease attention directed stimulus poor stimulus experimental result reproduced model v neuron assumption attention modulates activity local interneuron network v model neuron received stimulusspecific asynchronous excitation v synchronous inhibitory input two local interneuron network v interneuron network driven stimulusspecific excitatory input v modulated projection frontal eye field stimulus competition present delay arrival time synchronous volley interneuron network small delay firing rate close rate elicited preferred stimulus alone whereas larger delay approached firing rate poor stimulus either stimulus presented alone neuron response altered change delay model suggests topdown attention bias competition v column control v neuron changing relative timing inhibition rather change degree synchrony interneuron network mechanism proposed attentional modulation firing rate gain modulation inhibitory interference likely general applicability cortical information processing
q-bio.NC,although recent neurophysiological experiment suggest synchronous neural activity involved perceptual cognitive process functional role coherent neuronal behavior well understood first step clarifying role investigate temporal coherence certain neuronal activity affect activity pattern neural network using simple network leaky integrateandfire neuron study effect synchronized incoming spike functioning two mechanism typically used model neural system winnertakeall competition associative memory demonstrate pair switch undergone incoming spike asynchronous synchronous back asynchronous trigger transition network one state another state case associative memory example switching control timing next recalling whereas firing rate pattern asynchronous state prepares network next retrieval pattern
q-bio.NC,larval zebrafish exhibit variety complex undulatory swimming pattern repertoire controlled neuron projecting brain spinal cord understanding descending control signal shape output spinal circuit however nontrivial therefore developed segmental oscillator model using neuron investigate system found adjusting strength nmda glycinergic synapsis enabled generation oscillation tailbeat frequency range exhibited different larval swim pattern addition developed kinematic model visualize complex axial bending pattern used prey capture
q-bio.NC,brain model focus associative memory calculation capability experimentally inaccessible using physiological method present model explaining basic feature electroencephalogram eeg model based electrical network threshold firing plasticity synapsis reproduces robustly measured exponent medical eeg spectrum solid evidence selforganized criticality result also valid smallworld lattice propose universal scaling behaviour characterizes many physiological signal spectrum brain controlled activity
q-bio.NC,introduction two key dimension mind understanding responding anothers mental state empathizing analysing lawful behaviour systemizing method two questionnaire systemizing quotient sq empathy quotient eq administered normal control group group individual asperger syndrome highfunctioning autism hfa multivariate correlation joint score analysed using principal component analysis result principal component wellapproximated sum difference sq eq score difference score corresponded sex difference within control group also separated ashfa group showed stronger systemizing control group belowaverage empathy sum score show sex difference distinguish ashfa group conclusion test reliably sex brain correlation show empathizing systemizing independent compete neurally combined score eq sq quantifies deficit autism spectrum condition
q-bio.NC,experimental result recent year shown adult neurogenesis significant phenomenon mammalian brain little known however functional role played generation destruction neuron context adult brain propose two model new projection neuron incorporated show model using incorporation removal neuron computational tool possible achieve higher computational efficiency purely static synapselearning driven network also discus implication understanding role adult neurogenesis specific brain area
q-bio.NC,two recent paper rudolph destexhe neural comp bf neural comp press studied leaky integrator model ie rccircuit driven correlated colored gaussian conductance noise gaussian current noise first paper derived expression stationary probability density membrane voltage second paper expression modified cover larger parameter regime show standard analysis solvable limit case whitenoise limit additive multiplicative noise source slow multiplicative noise additive noise numerical simulation first result hold general colorednoise case uncover error made derivation fokkerplanck equation probability density furthermore demonstrate analytically including exact integral expression timedependent mean value voltage comparison simulation result extended expression probability density work much better still solve exactly full colorednoise problem also show stronger synaptic input stationary mean value linear voltage model may diverge give exact condition relating system parameter take place
q-bio.NC,qualitatively real network brain could characterized small world sense structure connection intermediate extreme orderly geometric arrangement geometryindependent random mesh small world defined precisely term mean path length clustering coefficient precise description useful better understand type connectivity affect memory retrieval simulated autoassociative memory network integrateandfire unit positioned ring network connectivity varied parametrically ordered random find network retrieves connectivity close random display characteristic behavior ordered net localized bump activity connectivity close ordered recent analytical work show two behaviour coexist network simple thresholdlinear unit leading localized retrieval state find tend mutually exclusive behaviour however integrateandfire unit moreover transition two occurs value connectivity parameter simply related notion small world
q-bio.NC,investigate performance sparselyconnected network integrateandfire neuron ultrashort term information processing exploit fact population activity network balanced excitation inhibition switch oscillatory firing regime state asynchronous irregular firing quiescence depending rate external background spike find term information buffering network performs best moderate nonzero amount noise analogous phenomenon stochastic resonance performance decrease higher lower noise level optimal amount noise corresponds transition zone quiescent state regime stochastic dynamic provides potential explanation role nonoscillatory population activity simplified model cortical microcircuit
q-bio.NC,randomly connected network pulsecoupled element timedependent input signal buffered short time studied signal buffering property simulated network function network state characterized lyapunov exponent microscopic dynamic macroscopic activity derived meanfield theory network element receive signal signal buffering delay comparable intrinsic time constant network element explained macroscopic property work best phase transition chaos however percent network unit receive common timedependent signal signal buffering property improve longer attributed macroscopic dynamic
q-bio.NC,timingbased neural code neuron emit action potential precise moment time use supervised learning paradigm derive synaptic update rule optimizes via gradient ascent likelihood postsynaptic firing one several desired firing time find optimal strategy downregulating synaptic efficacy described twophase learning window similar spiketiming dependent plasticity stdp presynaptic spike arrives desired postsynaptic spike timing optimal learning rule predicts synapse become potentiated dependence potentiation spike timing directly reflects time course excitatory postsynaptic potential presence amplitude depression synaptic efficacy reversed spike timing depends constraint implemented optimization problem two different constraint ie control postsynaptic rate control temporal localityare discussed
q-bio.NC,recording area v monkey revealed focus attention visual stimulus within receptive field cortical neuron two distinct change occur firing rate neuron change increase coherence spike local field potential gammafrequency range hz hypothesis explored observed effect attention could consequence change synchrony local interneuron network performed computer simulation hodgkinhuxley type neuron driven constant depolarizing current representing visual stimulation modulatory inhibitory input representing effect attention via local interneuron network observed neuron firing rate coherence output spike train synaptic input modulated degree synchrony inhibitory input model suggest observed change firing rate coherence neuron visual cortex could controlled topdown input regulated coherence activity local inhibitory network discharging gamma frequency
q-bio.NC,characterize computation motion fly visual system mapping high dimensional space signal retinal photodetector array probability generating action potential motion sensitive neuron approach problem identifies low dimensional subspace signal within neuron sensitive sample subspace visualize nonlinear structure mapping result illustrate computational strategy predicted system make optimal motion estimate given physical noise source detector array generally hypothesis neuron sensitive low dimensional subspace input formalizes intuitive notion feature selectivity suggests strategy characterizing neural processing complex naturalistic sensory input
q-bio.NC,varied sensory system use noise order enhance detection weak signal conjectured literature effect known stochastic resonance may take place central cognitive process memory retrieval arithmetical multiplication show simplified model cortical tissue complex arithmetical calculation carried enhanced presence stochastic background performance shown positively correlated susceptibility network defined sensitivity variation mean input nontrivial arithmetic task multiplication stochastic resonance emergent property microcircuitry model network
q-bio.NC,find role wiring cost organization neural network nematode textitcaenorhapditis elegans textitc elegans build neuronal map textitc elegans based geometrical position neuron define cost interneuronal euclidean distance textitd show wiring probability decay exponentially function textitd using edge exchanging method component placement optimization scheme show position neuron randomly distributed organized reduce total wiring cost furthermore numerically study tradeoff wiring cost performance hopfield model neural network
q-bio.NC,work analyze solution simple system coupled phase oscillator connectivity learned dynamically model inspired process learning birdsong oscine bird oscillator act generator basic rhythm drive slave oscillator responsible different motor action driving signal arrives driven oscillator two different pathway one direct pathway one reinforcement pathway signal arrives delayed coupling coefficient driving oscillator slave one evolve time following hebbianlike rule discus condition driven oscillator capable learning lock driver resulting phase difference connectivity function delay reinforcement around specific delay system capable generate dramatic change phase difference driver driven system discus dynamical mechanism responsible effect possible application learning scheme
q-bio.NC,wish discriminate spike sequence based degree irregularity purpose search rational expression quadratic function consecutive interspike interval efficiently measure spiking irregularity natural assumption functional form coefficient parameterized single parameter parameter determined maximize mutual information distribution coefficient computed spike sequence derived different renewal point process find local variation interspike interval lv neural comput vol pp nearly optimal whose intrinsic irregularity close experimental data
q-bio.NC,study described dissertation attempted address cellular mechanism information storage brain work focused primarily postsynaptic event occur induction longterm potentiation ltp longterm depression ltd schaffer collateralca synapse hippocampus explored various aspect role postsynaptic ca induction ltp ltd using extracellular wholecell recording technique well fluorescence imaging ca also examined possible role modulation dendritic k channel induction ltp
q-bio.NC,fitzhughnagumo equation used caricature hodgkinhuxley equation neuron firing better understand essential dynamic interaction membrane potential restoring force capture qualitatively general property excitable membrane even though simplicity allows valuable insight gained accuracy reproducing real experimental result limited paper utilize modified version fitzhughnagumo equation model spatial propagation neuron firing assume propagation least partially caused crossdiffusion connection potential recovery variable show crossdiffusion version model besides giving rise typical fast traveling wave solution exhibited original diffusion fitzhughnagumo equation also give rise slow traveling wave solution analyze possible traveling wave solution fitzhughnagumo equation crossdiffusion term show exists threshold crossdiffusion coefficient maximum value given speed propagation bound area normal impulse propagation possible
q-bio.NC,electroencephalograph eeg analysis enables neuronal behavior section brain examined behavior nonlinear nonlinear tool used glean information brain behavior aid diagnosis sleep abnormality obstructive sleep apnea syndrome osas paper sleep eeg set normal mild osas child evaluated nonlinear behaviour consider behaviour brain change sleep stage normal osas child
q-bio.NC,study analytically numerically effect presynaptic noise transmission information attractor neural network noise occurs shorttime scale compared neuron dynamic produce shorttime synaptic depression inspired recent neurobiological finding show synaptic strength may either increase decrease shorttime scale depending presynaptic activity thus describe mechanism fast presynaptic noise enhances neural network sensitivity external stimulus reason general presynaptic noise induces nonequilibrium behavior consequently space fixed point qualitatively modified way system easily scape attractor result model show addition pattern recognition class identification categorization may relevant understanding brain complex task
q-bio.NC,investigate stimulusdependent tuning property noisy ionic conductance model intrinsic subthreshold oscillation membrane potential associated spike generation depolarization applied current model exhibit subthreshold oscillatory activity occasional spike generation oscillation reach spike threshold consider amount applied current noise intensity variation maximum conductance value scaling different temperature range alter response model respect voltage trace interspike interval statistic mean spike frequency curve demonstrate subthreshold oscillatory neuron presence noise sensitively also selectively tuned stimulusdependent variation model parameter
q-bio.NC,studied neural automaton neurobiologically inspired cellular automaton exhibit chaotic itinerancy among different stored pattern memory consequence activitydependent synaptic fluctuation continuously destabilize attractor induce irregular hopping possible attractor nature resulting irregularity depends dynamic detail namely intensity synaptic noise number site network synchronously updated time step varying detail different regime occur regular chaotic absence external agent chaotic behavior may turn regular tuning noise intensity argued similar mechanism might origin selfcontrol chaos natural system
q-bio.NC,participatory environmental management plan prepared tuzla lake turkey fuzzy cognitive mapping approach used obtain stakeholder view desire cognitive map prepared stakeholder villager local decisionmakers government nongovernment organization ngo official graph theory index statistical method whatif simulation used analysis mentioned variable livelihood agriculture animal husbandry central variable agriculture local people villager local decisionmakers education ngo government official stakeholder agreed livelihood increased agriculture animal husbandry hunting decreased bird wildlife although local people focused livelihood ngo government official focused conservation tuzla lake education local people stakeholder indicated conservation status tuzla lake strengthened conserve ecosystem biodiversity may negatively impacted agriculture irrigation stakeholder mentioned salt extraction ecotourism carpet weaving alternative economic activity cognitive mapping provided effective tool inclusion stakeholder view ensured initial participation environmental planning policy making
q-bio.NC,behavior result integration ongoing sensory signal contextual information various form past experience expectation current goal etc thus response specific stimulus say ringing doorbell varies depending whether home someone el house neural basis flexibility mechanism capable selecting contextdependent way adequate response given stimulus one possibility based nonlinear neural representation context information regulates gain stimulusevoked response explore property mechanism mean three hypothetical visuomotor task study class neural network model one several possible stimulusresponse map rule selected according context underlying mechanism based gain modulation three key feature modulating sensory response equivalent switching different subpopulation neuron context need represented continuously although advantageous generalization contextdependent selection independent discriminability stimulus case contextual cue quickly turn sensorymotor map effectively changing functional connectivity input output network model predicts sensory response nonlinearly modulated arbitrary context signal found behavioral situation involve choosing switching multiple sensorymotor map
q-bio.NC,network dynamical system concurrent synchronization regime multiple group fully synchronized element coexist brain concurrent synchronization may occur several scale multiple rhythm interacting functional assembly combining neural oscillator many different type mathematically stable concurrent synchronization corresponds convergence flowinvariant linear subspace global state space derive general condition convergence occur globally exponentially also show mild condition global convergence concurrently synchronized regime preserved basic system combination negative feedback hierarchy stable concurrently synchronized aggregate arbitrary size constructed robustness stable concurrent synchronization variation individual dynamic also quantified simple application result classical question system neuroscience robotics discussed
q-bio.NC,study learning rule based upon temporal correlation weighted learning kernel incoming spike internal state postsynaptic neuron building upon previous study spike timing dependent synaptic plasticity citekgvhwkgvhvh learning rule synaptic weight wij dot wijt epsilon intinftyinfty fractl intttlt summu deltataustjmu utau dtau gammasds tjmu arrival time spike presynaptic neuron j function ut describes state postsynaptic neuron thus spiketriggered average contained inner integral weighted kernel gamma learning window positive negative negative positive value time diffence post presynaptic activity antisymmetry assumption learning window enables u derive analytical expression general class neuron model study change inputoutput relationship following synaptic weight change genuinely nonlinear effect citesma
q-bio.NC,attention directed receptive field v neuron contrast response curve shifted lower contrast value reynolds et al neuron attention also increase coherence neuron responding stimulus fry et al science studied firing rate synchrony densely interconnected cortical network varied contrast modulated attention found increased driving current excitatory neuron increased overall firing rate network whereas variation driving current inhibitory neuron modulated synchrony network explain synchrony modulation term locking phenomenon ratio excitatory inhibitory firing rate approximately constant range driving current value explored hypothesis contrast represented primarily drive excitatory neuron whereas attention corresponds reduction driving current inhibitory neuron using hypothesis model reproduces following experimental observation firing rate excitatory neuron increase contrast high contrast stimulus firing rate saturates network synchronizes attention shift contrast response curve lower contrast value attention lead stronger synchronization start lower value contrast compared attendaway condition addition predicts attention increase delay inhibitory excitatory synchronous volley produced network allowing stimulus recruit downstream neuron
q-bio.NC,emergence mental state neural state partitioning neural phase space analyzed term symbolic dynamic welldefined mental state provide context inducing criterion structural stability neurodynamics implemented particular partition lead distinguished subshifts finite type either cyclic irreducible cyclic shift correspond asymptotically stable fixed point limit torus whereas irreducible shift obtained generating partition mixing hyperbolic system stability criterion applied discussion neural correlate consiousness definition macroscopic neural state aspect symbol grounding problem particular shown compatible mental description topologically equivalent neurodynamical description emerge partition neural phase space generating case mental description incompatible complementary consequence result integration unification cognitive science psychology respectively indicated
q-bio.NC,present new interpretation encoding information period input signal spiketrains individual sensory neuronal system spiketrain could described waveform sample input signal lock sample point wave crest randomness based simulation hodgkinhuxley hh neuron responding periodic input demonstrate random sampling proper encoding method medium frequency region since power spectrum reconstructed spiketrains identical neural signal
q-bio.NC,paper develops highly simplified model analyze phenomenon sleep motivated crick suggestion sleep brain way taking trash suggestion supported emerging evidence consider problem filling emptying tank given time tank may take external resource fill resource available time may empty filling phase correspond information input environment input material general emptying phase correspond processing resource given resourceavailablility profile time interval develop canonical algorithm determining fillempty profile produce maximum quantity processed resource end time interval algorithm readily follows periodically oscillating resourceavailability profile optimal fillempty strategy given fill period resource available followed empty period resource cycling behavior analogous wakesleep cycle organismal life generally nocturnal sleep phase period information collected day activity may processed sleep cycle mechanism organism process maximal amount information daily cycle model exhibit phenomenon analogous microsleeps behavior associated breakdown sleep pattern
q-bio.NC,study examines cell death proliferation white matter neonatal stroke postnatal day injured rat marked reduction myelin basic protein mbp immunostaining mainly corresponding numerous pyknotic immature oligodendrocyte tunelpositive astrocyte ipsilateral external capsule contrast substantial restoration mbp indicated mbp ratio lefttoright occurred cingulum p hour recovery compared agematched control ki immunostaining revealed first peak newlygenerated cell dorsolateral hippocampal subventricular zone cingulum hour reperfusion double immunofluorescence revealed kipositive cell astrocyte hour ng preoligodendrocytes hour recovery microglia infiltration occurs several day cingulum huge quantity macrophage reached subcortical white matter engulfed immature oligodendrocyte overall result suggest persistent activation microglia involves chronic component immunoinflammation overwhelms repair process contributes cystic growth developing brain
q-bio.NC,present method estimating gradient objective function respect synaptic weight spiking neural network method work measuring fluctuation objective function response dynamic perturbation membrane conductance neuron compatible recurrent network conductancebased model neuron dynamic synapsis method interpreted biologically plausible synaptic learning rule dynamic perturbation generated special class empiric synapsis driven random spike train external source
q-bio.NC,network living neuron exhibit avalanche mode activity experimentally found organotypic culture present model based selforganized criticality taking account brain plasticity able reproduce spectrum electroencephalogram eeg model consists electrical network threshold firing activitydependent synapse strenghts system exhibit avalanche activity power law distributed analysis power spectrum electrical signal reproduces robustly power law behaviour exponent experimentally measured eeg spectrum value exponent found smallworld lattice leaky neuron indicating universality hold wide class brain model
q-bio.NC,natural sound described dynamic change envelope amplitude carrier frequency corresponding amplitude modulation frequency modulation fm respectively although neural response fm sound extensively studied animal human uncertain corepresented changed simultaneously independently typical ecologically natural signal study elucidates neural coding sound human auditory cortex using magnetoencephalography meg using stimulus sinusoidal modulated envelope fam hz carrier frequency ffm hz demonstrated fm stimulus dynamic corepresented neural code human auditory cortex stimulus dynamic represented neurally encoding auditory steady state response assr fam sound slowly changing carrier frequency ffm hz shown stimulus fm dynamic tracked phase assr demonstrating neural phase modulation pm encoding stimulus carrier frequency sound faster carrier frequency change ffm hz shown modulation encoding stimulus fm dynamic persists neural encoding longer purely pm result consistent recruitment additional neural encoding original neural pm encoding indicating amplitude phase assr fam track stimulus fm dynamic neural model suggested account observation
q-bio.NC,quian quiroga et al nature recently discovered neuron appear characteristic grandmother gm cell quantitatively ass compatibility data gmcell hypothesis show contrary general impression gmcell representation informationtheoretically efficient must accompanied cell giving distributed coding input present general method deduce sparsity distribution whole neuronal population sample use show two population cell distributedcode population le cell much sparsely responding population putative gm cell allowance number undetected silent cell find putative gm cell code category sufficient classic gm cell gmlike cell coding memory quantify strong bias detection gm cell show consistency result previous measurement find distributed coding discus consequence architecture neural system synaptic connectivity statistic neural firing
q-bio.NC,report investigate synchronization temporal activity electrically coupled neural network model electrical coupling established homotypic static gapjunctions connexin two distinct network topology namely em sparse random network srn em fully connected network fcn used establish connectivity strength connectivity fcn governed em mean gap junctional conductance mu case srn overall strength connectivity governed em density connection delta connection strength two neuron synchronization network increasing gap junctional strength varying population size investigated observed network em abruptly make transition weakly synchronized well synchronized regime delta mu exceeds critical value also observed delta mu value used achieve synchronization decrease increasing network size
q-bio.NC,main feature family efficient algorithm recognition classification complex pattern briefly reviewed inspired observation fast synaptic noise essential processing information brain
q-bio.NC,study effect competition shortterm synaptic depression facilitation dynamical property attractor neural network using monte carlo simulation mean field analysis depending balance depression facilitation noise network display different behaviour including associative memory switching activity different attractor conclude synaptic facilitation enhances attractor instability way intensifies system adaptability external stimulus agreement experiment ii favour retrieval information le error shorttime interval
q-bio.NC,present neurobiologicallyinspired stochastic cellular automaton whose state jump time attractor corresponding series stored pattern jumping varies regular chaotic model parameter modified resulting irregular behavior mimic state attention system show great adaptability changing stimulus consequence model shorttime presynaptic noise induces synaptic depression discus result meanfield analysis monte carlo simulation
q-bio.NC,studied autoassociative network synapsis noisy time scale much shorter one neuron dynamic model presynaptic noise cause postsynaptic depression recently observed neurobiological system result nonequilibrium condition network sensitivity external stimulus enhanced particular fixed point qualitatively modified system may easily scape attractor result addition pattern recognition model useful class identification categorization
q-bio.NC,present model olfactory coding based spatial representation glomerular response model distinct odorants activate specific subset glomerulus dependent upon odorants chemical identity concentration glomerular response specificity understood statistically based experimentally measured distribution detection threshold simple version model glomerular response binary onoff model allows u account quantitatively following result humanrodent olfactory psychophysics noticeable difference perceived concentration single odor weber ratio dcc number simultaneously perceived odor high extensive lesion olfactory bulb lead significant change detection discrimination threshold conclude combinatorial code based binary glomerular response sufficient account discrimination capacity mammalian olfactory system
q-bio.NC,recently spike timing dependent plasticity observed inhibitory synapse layer ii entorhinal cortex rule provides interesting zero region delta ttposttpre addition dynamic range rule lie gamma frequency band propose robust mechanism based observed synaptic plasticity rule inhibitory synapsis two mutually coupled interneurons phase lock synchrony presence intrisic heterogeneity firing study stability phase locked solution defining map spike time dependent phase response curve coupled neuron finally present result robustness synchronization presence noise
q-bio.NC,using realistic model activity dependent dynamical synapsis standard integrate fire neuron model study analytically numerically condition postsynaptic neuron efficiently detects temporal coincidence spike arriving certain frequency n different afferent extend previous work considers synaptic depression important mechanism transmission information synapsis general situation including also synaptic facilitation study show facilitation enhances detection correlated signal arriving subset presynaptic excitatory neuron different degree correlation among subset presence facilitation allows better detection firing rate change finally also observed facilitation determines existence optimal input frequency allows best performance wide maximum range neuron firing threshold optimal frequency controlled mean facilitation parameter
q-bio.NC,study deterministic dynamic two time scale continuous state attractor network usual fast relaxation dynamic towards point attractor pattern add slow coupling dynamic make visited pattern loose stability leading itinerant behavior form punctuated equilibrium one find transition frequency matrix pattern show nontrivial statistical property chaotic itinerant regime show mixture input pattern temporally segmented itinerant dynamic viability combinatorial spatiotemporal neural code also demonstrated
q-bio.NC,demonstrate numerically brief burst consisting two six spike propagate stable manner onedimensional homogeneous feedforward chain nonbursting neuron excitatory synaptic connection result obtained two kind neuronal model leaky integrateandfire lif neuron hodgkinhuxley hh neuron five conductance range parameter maximum synaptic conductance kind chain found multiple attractor propagating burst attractor distinguished number spike total duration propagating burst result make plausible hypothesis sparse preciselytimed sequential burst observed projection neuron nucleus hvc singing zebra finch intrinsic causally related
q-bio.NC,examine response type ii excitable neuron train synaptic pulse function pulse frequency amplitude show resonant behavior characteristic type ii excitability already described harmonic input also present pulsed input mind study response neuron pulsed input train whose frequency varies continuously time observe receiving neuron synchronizes episodically input pulse whenever pulse frequency lie within neuron locking range propose behavior mechanism ratecode detection neuronal population result obtained numerical simulation morrislecar model electronic implementation fitzhughnagumo system evidencing robustness phenomenon
q-bio.NC,synfire chain network generate repeated spike pattern millisecond precision although synfire chain one activity propagation mode intensively analyzed several neuron model several stable propagation mode thoroughly investigated using leaky integrateandfire neuron model constructed layered associative network embedded memory pattern analyzed network dynamic fokkerplanck equation first addressed stability one memory pattern propagating spike volley showed memory pattern propagate pulse packet second investigated activity activated two different memory pattern simultaneous activation two memory pattern strength led propagating pattern mixed state contrast activation different strength pulse packet converged twopeak state finally studied effect preceding pulse packet following pulse packet following pulse packet modified original activated memory pattern converged twopeak state mixed state nonspike state depending time interval
q-bio.NC,preliminary research area biophysics appears indicate existence quantum entanglement nonlocality biological level human subject neuron derived human neural stem cell lack clear replicable finding especially human subject concerned result conflicting marginal correlation stimulated nonstimulated subject brainwave proposed go beyond use patterned photostimulation encompass either transcranial magnetic stimulation tm acupuncture one achieve simultaneity several different brain event stimulated nonstimulated subject rather one eegtype event
q-bio.NC,investigated model neural integrator based hysteretic unit connected positive feedback hysteresis assumed emerge intrinsic property cell consider recurrent network containing either bistable multistable neuron apply analysis oculomotor velocitytoposition neural integrator calculates eye position input carry information eye angular velocity using analysis system parameter space show following direction hysteresis neuronal response may reversed system recurrent connection compared case unconnected neuron thus nmda receptor based bistability firing rate saccade may higher saccade eye position suggest emergent property due presence global recurrent feedback reversal hysteresis occurs size hysteresis differs neuron neuron also relate macroscopic leak timeconstant integrator rate microscopic spontaneous noisedriven transition hysteretic unit finally argue presence neuron small hysteresis may remove threshold integration
q-bio.NC,argue observation neural data neuron area dmec rat fire whenever rat vertex regular triangular lattice tile space may using advanced numeral system reversibly encode rat position interpret measured dmec property within framework residue number system rn describe rn encoding break nonperiodic variable rat position set narrowly distributed periodic variable allows small set cell compactly represent efficiently update rat position high resolution large range show uniquely useful property rn encoding still hold encoded encoding quantity relaxed real number builtin uncertainty provide numerical functional estimate range resolution rat position uniquely encoded dmec use compact arithmeticfriendly numeral system encode metric variable propose happening dmec qualitatively different previously identified example coding brain discus numerous neurobiological implication prediction hypothesis
q-bio.NC,study transient regime typeii biophysical neuron model determine scaling behavior relaxation time tau near repetitive firing critical current tau simeq c icidelta hodgkinhuxley morrislecar model find critical exponent independent numerical integration time step system belong universality class delta appropriately chosen parameter fitzhughnagumo model present generic transient behavior critical region significantly smaller propose experiment may reveal nontrivial critical exponent squid axon
q-bio.NC,present article experimental result obtained dispositif de lenay localization task distal perception orientation estimation task proximal perception orientation cylinder plane last experiment virtual version lenay device used result used illustrate methodological theoretical proposal study cognitive sensorimotor process involved perception
q-bio.NC,staggerer sgsg mutation spontaneous deletion rora gene prevents translation ligandbinding domain lbd leading loss roralpha activity homozygous rorasgsg mutant mouse whose obvious phenotype ataxia associated cerebellar degeneration also display variety phenotype heterozygous rorasg able develop cerebellum qualitatively normal advancing age suffers significant loss cerebellar neuronal cell truncated protein synthesized mutated allele may play role rorasgsg rorasg determine effect life span true haploinsufficiency roralpha protein derived invalidation gene compared evolution purkinje cell number heterozygous rora knockout male rora wildtype counterpart month age also compared evolution purkinje cell number rora rorasg male month main finding rora mouse half dose protein synthesized deficit already established month change life span
q-bio.NC,paper propose model simulate functional aspect light adaptation retinal photoreceptors model however link specific stage detailed molecular process thought mediate adaptation real photoreceptors rather model photoreceptor selfadjusting integration device add properly amplified luminance signal integration process amplification obey switching behavior act locally shut integration process dependence internal state receptor mathematical structure model quite simple computational complexity quite low present result computer simulation demonstrate model adapts properly least four order input magnitude
q-bio.NC,dynamical wiring rewiring neural network carried activitydependent growth retraction axon dendrite guided gudance molecule released target cell experiencedependent structural change cortical microcurcuts lead change activity ie change information encoded specific patten external stimulation lead creation new synaptical connection neuron calcium influx controlled neuronal activity regulates process neurotrophic factor release neuron growth cone movement synapse differentiation developing neural system therefore activitydependent selfwiring serve basis structural plasticity cortical network considered form learning
q-bio.NC,hippocampus capacity reactivating recently acquired memory hypothesized one function sleep reactivation facilitation consolidation novel memory trace dynamic network process underlying reactivation remain however unknown show reactivation characterized local selfsustained activity network region may inherent property recurrent excitatoryinhibitory network heterogeneous structure entry reactivation phase mediated physiologically feasible regulation global excitability external input source reactivated component network formed induced network heterogeneity learning show structural change needed robust reactivation given network region well within known physiological parameter
q-bio.NC,intensitytuned auditory cortex neuron may formed intensitytuned synaptic excitation synaptic inhibition also shown enhance possibly even create intensitytuned neuron show using vivo whole cell recording pentobarbitalanesthetized rat intensitytuned neuron indeed created solely disproportionally large inhibition high intensity without intensitytuned excitation since inhibition essentially cortical origin neuron provide example auditory featureselectivity arising de novo cortex
q-bio.NC,learning ability learn important factor development evolutionary process depending level complexity learning strongly vary associative learning explain simple learning behaviour much sophisticated strategy seem involved complex learning task particularly evident machine learning theory reinforcement learning statistical learning equally show trying model natural learning behaviour general setting modelling learning process statistical aspect relevant provided neural network nn paradigm particular interest natural learning experience situation nn learning model incorporate elementary learning mechanism based neurophysiological analogy hebb rule lead quantitative result concerning dynamic learning process hebb rule however directly applied case particular realistic problem delayed reinforcement sophistication algorithm rapidly increase want present model cope non trivial task still elementary based procedure one may think natural without appeal higher strategy show capability model provide good learning many different setting may help therefore understanding basic feature learning
q-bio.NC,algorithm simple feedback neural circuit representing brain area rapidly carry often adequate solve easy problem difficult problem return incorrect answer new excitatoryinhibitory circuit model associative memory display common human problem failing rapidly find memory small clue present memory model related computational network solving sudoku puzzle produce answer contain implicit checkbits representation information across neuron allowing rapid evaluation whether putative answer correct incorrect computation related visual popout fact may account strong psychological feeling right wrong retrieve nominal memory minimal clue information allows difficult computation memory retrieval done serial fashion using fast limited capability computational module multiple time mathematics excitatoryinhibitory circuit associative memory sudoku understood term energy lyapunov function described detail
q-bio.NC,optimal pattern synaptic conductance spike generation central neuron subject considerable interest ideally conductance time course extracted membrane potential vm activity difficult nonlinear contribution conductance vm render estimation membrane equation extremely sensitive outline solution problem based discretization time axis procedure extract time course excitatory inhibitory conductance solely analysis vm activity test method calculating spiketriggered average synaptic conductance using numerical simulation integrateandfire model subject colored conductance noise procedure also tested successfully biological cortical neuron using conductance noise injected dynamicclamp method allow extraction synaptic conductance vm recording vivo
q-bio.NC,eye movement behavioral response involved task complicated natural image classification report confirms pro antisaccades used volunteer designate target animal nontarget image centered degree fixation point correct response participant responded target millisecond average starting quick millisecond furthermore tracking gaze position considered powerful method study recognition saccade response time ocular dynamic event around response time calculated data sampled time per second hilbert transform applied obtain analytic signal horizontal gaze position amplitude phase used describe difference saccade may testify recognition process
q-bio.NC,try perform geometrization cognitive science psychology representing information state cognitive system point mental space given hierarchic madic tree association represented ball idea collection ball consider dynamic idea based lifting dynamic mental point apply dynamical model modeling flow unconscious conscious information human brain series model model consider cognitive system increasing complexity psychological behavior determined structure flow association idea
q-bio.NC,response synapsis neocortex show highly stochastic nonlinear behavior microscopic dynamic underlying behavior computational consequence natural pattern synaptic input explained conventional macroscopic model deterministic ensemble mean dynamic introduce correlation entropy synaptic inputoutput map measure synaptic reliability explicitly includes microscopic dynamic applying experimental data find cortical synapsis show lowdimensional chaos driven natural input pattern
q-bio.NC,paper show music composition brain function revealed electroencephalogram eeg analysis renewal nonpoisson process living nonergodic dominion reach important conclusion process data minimum spanning tree method detect significant event thereby building sequence time time series analyze show case eeg music composition significant event signature nonpoisson renewal process conclusion reached using technique statistical analysis recently developed group aging experiment ae first find case distance two consecutive event described nonexponential histogram thereby proving nonpoisson nature process corresponding survival probability psit well fitted stretched exponential psit propto expgamma talpha alpha second step rest adoption ae show renewal process show renewal stretched exponential emerging tip iceberg whose underwater part slow tail inverse power law structure power index mu alpha find eeg music composition yield mu basis recently discovered complexity matching effect according complex system mu responds complex driving signal p mup mu conclude result analysis may explain influence music human brain
